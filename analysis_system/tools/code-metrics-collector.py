#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä»£ç æŒ‡æ ‡æ”¶é›†å·¥å…·

ç”¨äºè‡ªåŠ¨æ”¶é›†Pythoné¡¹ç›®çš„åŸºç¡€ä»£ç æŒ‡æ ‡

ä½¿ç”¨æ–¹æ³•:
python code-metrics-collector.py --project-path /path/to/project --output metrics.json
"""

import os
import ast
import json
import argparse
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict


@dataclass
class FileMetrics:
    """å•ä¸ªæ–‡ä»¶çš„æŒ‡æ ‡"""

    file_path: str
    lines_of_code: int
    blank_lines: int
    comment_lines: int
    function_count: int
    class_count: int
    import_count: int
    max_complexity: int
    avg_complexity: float


@dataclass
class ProjectMetrics:
    """é¡¹ç›®æ•´ä½“æŒ‡æ ‡"""

    project_path: str
    total_files: int
    python_files: int
    total_lines: int
    code_lines: int
    blank_lines: int
    comment_lines: int
    total_functions: int
    total_classes: int
    total_imports: int
    avg_file_length: float
    max_file_length: int
    complexity_distribution: Dict[str, int]


class ComplexityAnalyzer(ast.NodeVisitor):
    """è®¡ç®—åœˆå¤æ‚åº¦çš„ASTè®¿é—®å™¨"""

    def __init__(self):
        self.complexity = 1  # åŸºç¡€å¤æ‚åº¦ä¸º1

    def visit_If(self, node):
        self.complexity += 1
        self.generic_visit(node)

    def visit_While(self, node):
        self.complexity += 1
        self.generic_visit(node)

    def visit_For(self, node):
        self.complexity += 1
        self.generic_visit(node)

    def visit_Try(self, node):
        self.complexity += 1
        self.generic_visit(node)

    def visit_ExceptHandler(self, node):
        self.complexity += 1
        self.generic_visit(node)

    def visit_With(self, node):
        self.complexity += 1
        self.generic_visit(node)


class CodeMetricsCollector:
    """ä»£ç æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.logger = self._setup_logger()

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(__name__)
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def analyze_file(self, file_path: Path) -> Optional[FileMetrics]:
        """åˆ†æå•ä¸ªPythonæ–‡ä»¶"""
        try:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                content = f.read()

            lines = content.split("\n")
            total_lines = len(lines)

            # ç»Ÿè®¡ä»£ç è¡Œã€ç©ºè¡Œã€æ³¨é‡Šè¡Œ
            code_lines = 0
            blank_lines = 0
            comment_lines = 0

            for line in lines:
                stripped = line.strip()
                if not stripped:
                    blank_lines += 1
                elif stripped.startswith("#"):
                    comment_lines += 1
                else:
                    code_lines += 1

            # è§£æAST
            try:
                tree = ast.parse(content)
            except SyntaxError as e:
                self.logger.warning(f"è¯­æ³•é”™è¯¯ {file_path}: {e}")
                return None

            # ç»Ÿè®¡å‡½æ•°ã€ç±»ã€å¯¼å…¥
            function_count = 0
            class_count = 0
            import_count = 0
            complexities = []

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    function_count += 1
                    # è®¡ç®—å‡½æ•°å¤æ‚åº¦
                    analyzer = ComplexityAnalyzer()
                    analyzer.visit(node)
                    complexities.append(analyzer.complexity)
                elif isinstance(node, ast.ClassDef):
                    class_count += 1
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    import_count += 1

            # è®¡ç®—å¤æ‚åº¦ç»Ÿè®¡
            max_complexity = max(complexities) if complexities else 0
            avg_complexity = (
                sum(complexities) / len(complexities) if complexities else 0
            )

            return FileMetrics(
                file_path=str(file_path),
                lines_of_code=code_lines,
                blank_lines=blank_lines,
                comment_lines=comment_lines,
                function_count=function_count,
                class_count=class_count,
                import_count=import_count,
                max_complexity=max_complexity,
                avg_complexity=avg_complexity,
            )

        except Exception as e:
            self.logger.error(f"åˆ†ææ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def collect_project_metrics(self, project_path: Path) -> ProjectMetrics:
        """æ”¶é›†é¡¹ç›®çº§åˆ«çš„æŒ‡æ ‡"""
        python_files = []

        # æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶
        for py_file in project_path.rglob("*.py"):
            if not any(part.startswith(".") for part in py_file.parts):
                python_files.append(py_file)

        self.logger.info(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")

        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        file_metrics = []
        for py_file in python_files:
            metrics = self.analyze_file(py_file)
            if metrics:
                file_metrics.append(metrics)

        # è®¡ç®—é¡¹ç›®çº§åˆ«æŒ‡æ ‡
        total_files = len(file_metrics)
        total_lines = sum(
            m.lines_of_code + m.blank_lines + m.comment_lines for m in file_metrics
        )
        code_lines = sum(m.lines_of_code for m in file_metrics)
        blank_lines = sum(m.blank_lines for m in file_metrics)
        comment_lines = sum(m.comment_lines for m in file_metrics)
        total_functions = sum(m.function_count for m in file_metrics)
        total_classes = sum(m.class_count for m in file_metrics)
        total_imports = sum(m.import_count for m in file_metrics)

        # è®¡ç®—å¹³å‡å€¼
        avg_file_length = total_lines / total_files if total_files > 0 else 0
        max_file_length = (
            max(
                (m.lines_of_code + m.blank_lines + m.comment_lines)
                for m in file_metrics
            )
            if file_metrics
            else 0
        )

        # å¤æ‚åº¦åˆ†å¸ƒ
        all_complexities = []
        for metrics in file_metrics:
            if metrics.max_complexity > 0:
                all_complexities.append(metrics.max_complexity)

        complexity_distribution = {
            "low": sum(1 for c in all_complexities if 1 <= c <= 10),
            "medium": sum(1 for c in all_complexities if 11 <= c <= 20),
            "high": sum(1 for c in all_complexities if 21 <= c <= 50),
            "very_high": sum(1 for c in all_complexities if c > 50),
        }

        return ProjectMetrics(
            project_path=str(project_path),
            total_files=total_files,
            python_files=len(python_files),
            total_lines=total_lines,
            code_lines=code_lines,
            blank_lines=blank_lines,
            comment_lines=comment_lines,
            total_functions=total_functions,
            total_classes=total_classes,
            total_imports=total_imports,
            avg_file_length=round(avg_file_length, 2),
            max_file_length=max_file_length,
            complexity_distribution=complexity_distribution,
        )

    def save_metrics(self, metrics: ProjectMetrics, output_path: Path):
        """ä¿å­˜æŒ‡æ ‡åˆ°JSONæ–‡ä»¶"""
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(asdict(metrics), f, indent=2, ensure_ascii=False)

        self.logger.info(f"æŒ‡æ ‡å·²ä¿å­˜åˆ°: {output_path}")


def main():
    parser = argparse.ArgumentParser(description="Pythoné¡¹ç›®ä»£ç æŒ‡æ ‡æ”¶é›†å·¥å…·")
    parser.add_argument(
        "--project-path", type=str, required=True, help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="metrics.json",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„ (é»˜è®¤: metrics.json)",
    )
    parser.add_argument("--verbose", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†æ—¥å¿—")

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # éªŒè¯é¡¹ç›®è·¯å¾„
    project_path = Path(args.project_path)
    if not project_path.exists():
        print(f"é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨: {project_path}")
        return 1

    if not project_path.is_dir():
        print(f"é”™è¯¯: é¡¹ç›®è·¯å¾„ä¸æ˜¯ç›®å½•: {project_path}")
        return 1

    # æ”¶é›†æŒ‡æ ‡
    collector = CodeMetricsCollector()
    metrics = collector.collect_project_metrics(project_path)

    # ä¿å­˜ç»“æœ
    output_path = Path(args.output)
    collector.save_metrics(metrics, output_path)

    # æ˜¾ç¤ºæ‘˜è¦
    print(f"\nğŸ“Š é¡¹ç›®åˆ†ææ‘˜è¦:")
    print(f"é¡¹ç›®è·¯å¾„: {metrics.project_path}")
    print(f"Pythonæ–‡ä»¶æ•°: {metrics.python_files}")
    print(f"æ€»ä»£ç è¡Œæ•°: {metrics.code_lines}")
    print(f"å‡½æ•°æ•°é‡: {metrics.total_functions}")
    print(f"ç±»æ•°é‡: {metrics.total_classes}")
    print(f"å¹³å‡æ–‡ä»¶é•¿åº¦: {metrics.avg_file_length} è¡Œ")
    print(
        f"å¤æ‚åº¦åˆ†å¸ƒ: ä½({metrics.complexity_distribution['low']}) "
        f"ä¸­({metrics.complexity_distribution['medium']}) "
        f"é«˜({metrics.complexity_distribution['high']}) "
        f"æé«˜({metrics.complexity_distribution['very_high']})"
    )

    return 0


if __name__ == "__main__":
    exit(main())
