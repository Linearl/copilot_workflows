#!/usr/bin/env python3
"""
å·¥ä½œæµéªŒè¯å™¨ - è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„å·¥ä½œæµçš„è´¨é‡å’Œå®Œæ•´æ€§
æ”¯æŒè¯­æ³•æ£€æŸ¥ã€é€»è¾‘éªŒè¯ã€ä¾èµ–åˆ†æå’Œè´¨é‡è¯„ä¼°
"""

import os
import re
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Tuple
import logging

logger = logging.getLogger(__name__)


class WorkflowValidator:
    """å·¥ä½œæµéªŒè¯å™¨ä¸»ç±»"""

    def __init__(self):
        self.validation_results = {
            "syntax": {"passed": 0, "failed": 0, "issues": []},
            "logic": {"passed": 0, "failed": 0, "issues": []},
            "dependencies": {"passed": 0, "failed": 0, "issues": []},
            "quality": {"score": 0, "details": {}},
        }

    def validate_workflow(self, workflow_path: str) -> Dict[str, Any]:
        """
        å…¨é¢éªŒè¯å·¥ä½œæµ

        Args:
            workflow_path: å·¥ä½œæµç›®å½•è·¯å¾„

        Returns:
            éªŒè¯ç»“æœå­—å…¸
        """
        logger.info(f"å¼€å§‹éªŒè¯å·¥ä½œæµ: {workflow_path}")

        workflow_dir = Path(workflow_path)
        if not workflow_dir.exists():
            raise FileNotFoundError(f"å·¥ä½œæµè·¯å¾„ä¸å­˜åœ¨: {workflow_path}")

        # é‡ç½®éªŒè¯ç»“æœ
        self._reset_results()

        # è¯­æ³•éªŒè¯
        self.validate_syntax(workflow_path)

        # é€»è¾‘éªŒè¯
        self.validate_logic(workflow_path)

        # ä¾èµ–éªŒè¯
        self.validate_dependencies(workflow_path)

        # è´¨é‡è¯„ä¼°
        self.assess_quality(workflow_path)

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = self._generate_validation_report()

        logger.info("å·¥ä½œæµéªŒè¯å®Œæˆ")
        return report

    def _reset_results(self):
        """é‡ç½®éªŒè¯ç»“æœ"""
        self.validation_results = {
            "syntax": {"passed": 0, "failed": 0, "issues": []},
            "logic": {"passed": 0, "failed": 0, "issues": []},
            "dependencies": {"passed": 0, "failed": 0, "issues": []},
            "quality": {"score": 0, "details": {}},
        }

    def validate_syntax(self, workflow_path: str):
        """éªŒè¯è¯­æ³•æ­£ç¡®æ€§"""
        logger.info("æ‰§è¡Œè¯­æ³•éªŒè¯")

        workflow_dir = Path(workflow_path)

        # éªŒè¯Markdownæ–‡ä»¶
        for md_file in workflow_dir.glob("**/*.md"):
            self._validate_markdown_syntax(md_file)

        # éªŒè¯Pythonè„šæœ¬
        for py_file in workflow_dir.glob("**/*.py"):
            self._validate_python_syntax(py_file)

        # éªŒè¯PowerShellè„šæœ¬
        for ps_file in workflow_dir.glob("**/*.ps1"):
            self._validate_powershell_syntax(ps_file)

        # éªŒè¯JSONæ–‡ä»¶
        for json_file in workflow_dir.glob("**/*.json"):
            self._validate_json_syntax(json_file)

    def _validate_markdown_syntax(self, file_path: Path):
        """éªŒè¯Markdownè¯­æ³•"""
        try:
            content = file_path.read_text(encoding="utf-8")

            # æ£€æŸ¥æ ‡é¢˜å±‚æ¬¡
            self._check_heading_hierarchy(content, file_path)

            # æ£€æŸ¥é“¾æ¥å®Œæ•´æ€§
            self._check_link_integrity(content, file_path)

            # æ£€æŸ¥ä»£ç å—æ ¼å¼
            self._check_code_block_format(content, file_path)

            # æ£€æŸ¥åˆ—è¡¨æ ¼å¼
            self._check_list_format(content, file_path)

            self.validation_results["syntax"]["passed"] += 1

        except Exception as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "markdown_syntax",
                    "message": f"Markdownè¯­æ³•é”™è¯¯: {str(e)}",
                }
            )

    def _check_heading_hierarchy(self, content: str, file_path: Path):
        """æ£€æŸ¥æ ‡é¢˜å±‚æ¬¡ç»“æ„"""
        lines = content.split("\n")
        prev_level = 0

        for i, line in enumerate(lines, 1):
            if line.startswith("#"):
                level = len(line) - len(line.lstrip("#"))

                # æ£€æŸ¥å±‚æ¬¡è·³è·ƒ
                if level > prev_level + 1:
                    self.validation_results["syntax"]["issues"].append(
                        {
                            "file": str(file_path),
                            "line": i,
                            "type": "heading_hierarchy",
                            "message": f"æ ‡é¢˜å±‚æ¬¡è·³è·ƒ: ä» H{prev_level} ç›´æ¥è·³åˆ° H{level}",
                        }
                    )

                prev_level = level

    def _check_link_integrity(self, content: str, file_path: Path):
        """æ£€æŸ¥é“¾æ¥å®Œæ•´æ€§"""
        # æ£€æŸ¥å†…éƒ¨é“¾æ¥
        internal_links = re.findall(r"\[([^\]]+)\]\(#([^)]+)\)", content)

        # æå–æ‰€æœ‰æ ‡é¢˜é”šç‚¹
        anchors = set()
        for line in content.split("\n"):
            if line.startswith("#"):
                title = line.lstrip("# ").strip()
                anchor = self._generate_anchor(title)
                anchors.add(anchor)

        # éªŒè¯å†…éƒ¨é“¾æ¥
        for link_text, anchor in internal_links:
            if anchor not in anchors:
                self.validation_results["syntax"]["issues"].append(
                    {
                        "file": str(file_path),
                        "type": "broken_link",
                        "message": f"æ–­å¼€çš„å†…éƒ¨é“¾æ¥: [{link_text}](#{anchor})",
                    }
                )

        # æ£€æŸ¥å¤–éƒ¨æ–‡ä»¶é“¾æ¥
        file_links = re.findall(r"\[([^\]]+)\]\(([^#)]+\.md[^)]*)\)", content)
        for link_text, file_link in file_links:
            target_file = file_path.parent / file_link
            if not target_file.exists():
                self.validation_results["syntax"]["issues"].append(
                    {
                        "file": str(file_path),
                        "type": "broken_file_link",
                        "message": f"æ–­å¼€çš„æ–‡ä»¶é“¾æ¥: [{link_text}]({file_link})",
                    }
                )

    def _generate_anchor(self, title: str) -> str:
        """ç”Ÿæˆæ ‡é¢˜é”šç‚¹ - æ”¯æŒemojiæ ¼å¼"""
        # ç§»é™¤markdownæ ‡é¢˜æ ‡è®°
        anchor = title.lstrip("# ").strip()
        
        # å¯¹äºåŒ…å«emojiçš„æ ‡é¢˜ï¼Œé‡‡ç”¨Typoraå…¼å®¹æ ¼å¼
        # æ ¹æ®æ‚¨çš„ç¤ºä¾‹: [ğŸ“ å‡†å¤‡é˜¶æ®µ (Preparation Phase)](#ğŸ“-å‡†å¤‡é˜¶æ®µ-preparation-phase)
        # é”šç‚¹æ ¼å¼åº”è¯¥æ˜¯: emoji-åç»­æ–‡å­—-ç”¨è¿å­—ç¬¦è¿æ¥
        
        # ä¸è½¬æ¢ä¸ºå°å†™ï¼Œä¿æŒåŸå§‹å¤§å°å†™ï¼ˆé™¤äº†è¿å­—ç¬¦åŒ–ï¼‰
        
        # å°†ç©ºæ ¼æ›¿æ¢ä¸ºè¿å­—ç¬¦ï¼Œä½†ä¿ç•™emojiå’Œä¸­æ–‡å­—ç¬¦
        anchor = re.sub(r'\s+', '-', anchor)
        
        # ç§»é™¤ä¸éœ€è¦çš„ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™emojiã€ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€è¿å­—ç¬¦ã€æ‹¬å·
        # æ”¯æŒæ›´å¤šemojiå­—ç¬¦
        anchor = re.sub(r'[^\w\-\(\)ğŸ˜€-ï¿½ï¿½-ï¿½ğŸ€-ğŸ¿ï¿½-ï¿½ï¿½-ğŸ—¿ğŸ‘€-ğŸ‘¿ï¿½-ï¿½ï¿½-ï¿½ï¿½-ï¿½ğŸ¤€-ğŸ¤¿ğŸ¥€-ğŸ¥¿ğŸ¦€-ğŸ¦¿ğŸ§€-ğŸ§¿\u4e00-\u9fff]', '', anchor)
        
        # æ¸…ç†å¤šä½™çš„è¿å­—ç¬¦
        anchor = re.sub(r'-+', '-', anchor)
        anchor = anchor.strip('-')
        
        return anchor

    def _check_code_block_format(self, content: str, file_path: Path):
        """æ£€æŸ¥ä»£ç å—æ ¼å¼"""
        lines = content.split("\n")
        in_code_block = False

        for i, line in enumerate(lines, 1):
            if line.startswith("```"):
                if not in_code_block:
                    # å¼€å§‹ä»£ç å—
                    if line.strip() == "```":
                        self.validation_results["syntax"]["issues"].append(
                            {
                                "file": str(file_path),
                                "line": i,
                                "type": "code_block_language",
                                "message": "ä»£ç å—ç¼ºå°‘è¯­è¨€æ ‡è¯†",
                            }
                        )
                    in_code_block = True
                else:
                    # ç»“æŸä»£ç å—
                    in_code_block = False

    def _check_list_format(self, content: str, file_path: Path):
        """æ£€æŸ¥åˆ—è¡¨æ ¼å¼"""
        lines = content.split("\n")

        for i, line in enumerate(lines, 1):
            if re.match(r"^[\s]*[-*+]\s", line):
                # æ£€æŸ¥å‰åç©ºè¡Œ
                if (
                    i > 1
                    and lines[i - 2].strip() != ""
                    and not re.match(r"^[\s]*[-*+]\s", lines[i - 2])
                ):
                    self.validation_results["syntax"]["issues"].append(
                        {
                            "file": str(file_path),
                            "line": i,
                            "type": "list_format",
                            "message": "åˆ—è¡¨å‰éœ€è¦ç©ºè¡Œ",
                        }
                    )

    def _validate_python_syntax(self, file_path: Path):
        """éªŒè¯Pythonè¯­æ³•"""
        try:
            content = file_path.read_text(encoding="utf-8")
            compile(content, str(file_path), "exec")
            self.validation_results["syntax"]["passed"] += 1

        except SyntaxError as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "line": e.lineno,
                    "type": "python_syntax",
                    "message": f"Pythonè¯­æ³•é”™è¯¯: {e.msg}",
                }
            )
        except Exception as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "python_error",
                    "message": f"Pythonæ–‡ä»¶é”™è¯¯: {str(e)}",
                }
            )

    def _validate_powershell_syntax(self, file_path: Path):
        """éªŒè¯PowerShellè¯­æ³•"""
        try:
            # ä½¿ç”¨PowerShellæ£€æŸ¥è¯­æ³•
            result = subprocess.run(
                [
                    "powershell",
                    "-Command",
                    f'$null = Get-Content "{file_path}" | Out-String | Invoke-Expression',
                ],
                capture_output=True,
                text=True,
                timeout=10,
            )

            if result.returncode == 0:
                self.validation_results["syntax"]["passed"] += 1
            else:
                self.validation_results["syntax"]["failed"] += 1
                self.validation_results["syntax"]["issues"].append(
                    {
                        "file": str(file_path),
                        "type": "powershell_syntax",
                        "message": f"PowerShellè¯­æ³•é”™è¯¯: {result.stderr}",
                    }
                )

        except subprocess.TimeoutExpired:
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "powershell_timeout",
                    "message": "PowerShellè¯­æ³•æ£€æŸ¥è¶…æ—¶",
                }
            )
        except Exception as e:
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "powershell_error",
                    "message": f"PowerShellæ£€æŸ¥é”™è¯¯: {str(e)}",
                }
            )

    def _validate_json_syntax(self, file_path: Path):
        """éªŒè¯JSONè¯­æ³•"""
        try:
            content = file_path.read_text(encoding="utf-8")
            json.loads(content)
            self.validation_results["syntax"]["passed"] += 1

        except json.JSONDecodeError as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "line": e.lineno,
                    "type": "json_syntax",
                    "message": f"JSONè¯­æ³•é”™è¯¯: {e.msg}",
                }
            )

    def validate_logic(self, workflow_path: str):
        """éªŒè¯é€»è¾‘å®Œæ•´æ€§"""
        logger.info("æ‰§è¡Œé€»è¾‘éªŒè¯")

        workflow_dir = Path(workflow_path)

        # æŸ¥æ‰¾ä¸»å·¥ä½œæµæ–‡ä»¶
        main_workflow = self._find_main_workflow(workflow_dir)
        if not main_workflow:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {"type": "missing_main_workflow", "message": "æœªæ‰¾åˆ°ä¸»å·¥ä½œæµæ–‡ä»¶"}
            )
            return

        # éªŒè¯å·¥ä½œæµç»“æ„
        self._validate_workflow_structure(main_workflow)

        # éªŒè¯æ­¥éª¤å®Œæ•´æ€§
        self._validate_step_completeness(main_workflow)

        # éªŒè¯ç¡®è®¤æ£€æŸ¥ç‚¹
        self._validate_checkpoints(main_workflow)

        # éªŒè¯æ–‡ä»¶å¼•ç”¨
        self._validate_file_references(main_workflow, workflow_dir)

    def _find_main_workflow(self, workflow_dir: Path) -> Path:
        """æŸ¥æ‰¾ä¸»å·¥ä½œæµæ–‡ä»¶"""
        # æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶
        templates = list(workflow_dir.glob("*_template.md"))
        if templates:
            return templates[0]

        # æŸ¥æ‰¾workflow.md
        workflow_md = workflow_dir / "workflow.md"
        if workflow_md.exists():
            return workflow_md

        # æŸ¥æ‰¾README.md
        readme_md = workflow_dir / "README.md"
        if readme_md.exists():
            return readme_md

        return None

    def _validate_workflow_structure(self, workflow_file: Path):
        """éªŒè¯å·¥ä½œæµç»“æ„"""
        content = workflow_file.read_text(encoding="utf-8")

        required_sections = ["å·¥ä½œæµç®€ä»‹", "ç›®å½•ç»“æ„", "æ ‡å‡†æµç¨‹", "è‡ªåŠ¨ç”ŸæˆåŒºåŸŸ"]

        for section in required_sections:
            if section not in content:
                self.validation_results["logic"]["failed"] += 1
                self.validation_results["logic"]["issues"].append(
                    {
                        "file": str(workflow_file),
                        "type": "missing_section",
                        "message": f"ç¼ºå°‘å¿…éœ€ç« èŠ‚: {section}",
                    }
                )
            else:
                self.validation_results["logic"]["passed"] += 1

    def _validate_step_completeness(self, workflow_file: Path):
        """éªŒè¯æ­¥éª¤å®Œæ•´æ€§"""
        content = workflow_file.read_text(encoding="utf-8")

        # æŸ¥æ‰¾æ­¥éª¤å®šä¹‰
        steps = re.findall(r"### æ­¥éª¤(\d+)ï¼š(.+)", content)

        if not steps:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {
                    "file": str(workflow_file),
                    "type": "no_steps",
                    "message": "æœªæ‰¾åˆ°å·¥ä½œæµæ­¥éª¤å®šä¹‰",
                }
            )
            return

        # æ£€æŸ¥æ­¥éª¤è¿ç»­æ€§
        step_numbers = [int(step[0]) for step in steps]
        expected_numbers = list(range(1, len(step_numbers) + 1))

        if step_numbers != expected_numbers:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {
                    "file": str(workflow_file),
                    "type": "step_numbering",
                    "message": f"æ­¥éª¤ç¼–å·ä¸è¿ç»­: {step_numbers}",
                }
            )
        else:
            self.validation_results["logic"]["passed"] += 1

    def _validate_checkpoints(self, workflow_file: Path):
        """éªŒè¯ç¡®è®¤æ£€æŸ¥ç‚¹"""
        content = workflow_file.read_text(encoding="utf-8")

        # æŸ¥æ‰¾ç¡®è®¤æ£€æŸ¥ç‚¹
        checkpoints = re.findall(r"ğŸ¤.*?ç”¨æˆ·ç¡®è®¤æ£€æŸ¥ç‚¹", content)

        if len(checkpoints) < 2:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {
                    "file": str(workflow_file),
                    "type": "insufficient_checkpoints",
                    "message": f"ç¡®è®¤æ£€æŸ¥ç‚¹ä¸è¶³: æ‰¾åˆ°{len(checkpoints)}ä¸ªï¼Œå»ºè®®è‡³å°‘2ä¸ª",
                }
            )
        else:
            self.validation_results["logic"]["passed"] += 1

    def _validate_file_references(self, workflow_file: Path, workflow_dir: Path):
        """éªŒè¯æ–‡ä»¶å¼•ç”¨"""
        content = workflow_file.read_text(encoding="utf-8")

        # æŸ¥æ‰¾è„šæœ¬å¼•ç”¨
        script_refs = re.findall(r"`([^`]+\.(py|ps1|sh))`", content)

        for script_ref, ext in script_refs:
            script_path = workflow_dir / script_ref
            if not script_path.exists():
                self.validation_results["logic"]["failed"] += 1
                self.validation_results["logic"]["issues"].append(
                    {
                        "file": str(workflow_file),
                        "type": "missing_script",
                        "message": f"å¼•ç”¨çš„è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script_ref}",
                    }
                )
            else:
                self.validation_results["logic"]["passed"] += 1

    def validate_dependencies(self, workflow_path: str):
        """éªŒè¯ä¾èµ–å®Œæ•´æ€§"""
        logger.info("æ‰§è¡Œä¾èµ–éªŒè¯")

        workflow_dir = Path(workflow_path)

        # æ£€æŸ¥Pythonä¾èµ–
        self._check_python_dependencies(workflow_dir)

        # æ£€æŸ¥PowerShellæ¨¡å—
        self._check_powershell_modules(workflow_dir)

        # æ£€æŸ¥ç³»ç»Ÿä¾èµ–
        self._check_system_dependencies(workflow_dir)

    def _check_python_dependencies(self, workflow_dir: Path):
        """æ£€æŸ¥Pythonä¾èµ–"""
        requirements_file = workflow_dir / "requirements.txt"

        if requirements_file.exists():
            try:
                content = requirements_file.read_text(encoding="utf-8")
                packages = [
                    line.strip() for line in content.split("\n") if line.strip()
                ]

                for package in packages:
                    # éªŒè¯åŒ…åæ ¼å¼
                    if not re.match(r"^[a-zA-Z0-9-_]+([>=<]=?[\d.]+)?$", package):
                        self.validation_results["dependencies"]["failed"] += 1
                        self.validation_results["dependencies"]["issues"].append(
                            {
                                "file": str(requirements_file),
                                "type": "invalid_package",
                                "message": f"æ— æ•ˆçš„åŒ…åæ ¼å¼: {package}",
                            }
                        )
                    else:
                        self.validation_results["dependencies"]["passed"] += 1

            except Exception as e:
                self.validation_results["dependencies"]["failed"] += 1
                self.validation_results["dependencies"]["issues"].append(
                    {
                        "file": str(requirements_file),
                        "type": "requirements_error",
                        "message": f"requirements.txtè¯»å–é”™è¯¯: {str(e)}",
                    }
                )

        # æ£€æŸ¥Pythonè„šæœ¬ä¸­çš„import
        for py_file in workflow_dir.glob("**/*.py"):
            self._check_python_imports(py_file)

    def _check_python_imports(self, py_file: Path):
        """æ£€æŸ¥Pythonå¯¼å…¥"""
        try:
            content = py_file.read_text(encoding="utf-8")
            imports = re.findall(
                r"^(?:from\s+(\w+)|import\s+(\w+))", content, re.MULTILINE
            )

            for from_import, direct_import in imports:
                module = from_import or direct_import
                if module and not self._is_builtin_module(module):
                    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„åŒ…æ£€æŸ¥é€»è¾‘
                    self.validation_results["dependencies"]["passed"] += 1

        except Exception as e:
            self.validation_results["dependencies"]["failed"] += 1
            self.validation_results["dependencies"]["issues"].append(
                {
                    "file": str(py_file),
                    "type": "import_check_error",
                    "message": f"å¯¼å…¥æ£€æŸ¥é”™è¯¯: {str(e)}",
                }
            )

    def _is_builtin_module(self, module_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå†…ç½®æ¨¡å—"""
        builtin_modules = {
            "os",
            "sys",
            "re",
            "json",
            "logging",
            "datetime",
            "pathlib",
            "subprocess",
            "argparse",
            "unittest",
            "tempfile",
            "shutil",
        }
        return module_name in builtin_modules

    def _check_powershell_modules(self, workflow_dir: Path):
        """æ£€æŸ¥PowerShellæ¨¡å—ä¾èµ–"""
        for ps_file in workflow_dir.glob("**/*.ps1"):
            try:
                content = ps_file.read_text(encoding="utf-8")
                modules = re.findall(r"Import-Module\s+([^\s]+)", content)

                for module in modules:
                    self.validation_results["dependencies"]["passed"] += 1

            except Exception as e:
                self.validation_results["dependencies"]["failed"] += 1
                self.validation_results["dependencies"]["issues"].append(
                    {
                        "file": str(ps_file),
                        "type": "powershell_module_error",
                        "message": f"PowerShellæ¨¡å—æ£€æŸ¥é”™è¯¯: {str(e)}",
                    }
                )

    def _check_system_dependencies(self, workflow_dir: Path):
        """æ£€æŸ¥ç³»ç»Ÿä¾èµ–"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ç³»ç»Ÿå‘½ä»¤è°ƒç”¨
        command_patterns = [
            r'subprocess\.run\(["\']([^"\']+)["\']',
            r'os\.system\(["\']([^"\']+)["\']',
            r'Invoke-Expression\s+["\']([^"\']+)["\']',
        ]

        for file_path in workflow_dir.glob("**/*"):
            if file_path.suffix in [".py", ".ps1"]:
                try:
                    content = file_path.read_text(encoding="utf-8")

                    for pattern in command_patterns:
                        commands = re.findall(pattern, content)
                        for command in commands:
                            # è¿™é‡Œå¯ä»¥æ·»åŠ å‘½ä»¤å¯ç”¨æ€§æ£€æŸ¥
                            self.validation_results["dependencies"]["passed"] += 1

                except Exception:
                    pass  # å¿½ç•¥æ–‡ä»¶è¯»å–é”™è¯¯

    def assess_quality(self, workflow_path: str):
        """è¯„ä¼°å·¥ä½œæµè´¨é‡"""
        logger.info("æ‰§è¡Œè´¨é‡è¯„ä¼°")

        workflow_dir = Path(workflow_path)

        quality_scores = {
            "completeness": self._assess_completeness(workflow_dir),
            "usability": self._assess_usability(workflow_dir),
            "maintainability": self._assess_maintainability(workflow_dir),
            "performance": self._assess_performance(workflow_dir),
            "documentation": self._assess_documentation(workflow_dir),
            "extensibility": self._assess_extensibility(workflow_dir),
        }

        # è®¡ç®—ç»¼åˆåˆ†æ•°
        weights = {
            "completeness": 0.25,
            "usability": 0.20,
            "maintainability": 0.20,
            "performance": 0.15,
            "documentation": 0.10,
            "extensibility": 0.10,
        }

        total_score = sum(
            quality_scores[dimension] * weights[dimension]
            for dimension in quality_scores
        )

        self.validation_results["quality"]["score"] = total_score
        self.validation_results["quality"]["details"] = quality_scores

    def _assess_completeness(self, workflow_dir: Path) -> float:
        """è¯„ä¼°åŠŸèƒ½å®Œæ•´æ€§"""
        score = 0.0
        total_checks = 6

        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        required_files = ["README.md"]
        if any(
            workflow_dir.glob(pattern) for pattern in ["*_template.md", "*_workflow.md"]
        ):
            score += 1

        if any(workflow_dir.glob("README.md")):
            score += 1

        # æ£€æŸ¥è„šæœ¬æ–‡ä»¶
        if any(workflow_dir.glob("**/*.py")):
            score += 1

        if any(workflow_dir.glob("**/*.ps1")):
            score += 1

        # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶
        if any(workflow_dir.glob("**/test_*.py")):
            score += 1

        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        if any(workflow_dir.glob("**/*.json")) or any(workflow_dir.glob("**/*.yaml")):
            score += 1

        return (score / total_checks) * 10

    def _assess_usability(self, workflow_dir: Path) -> float:
        """è¯„ä¼°æ˜“ç”¨æ€§"""
        score = 0.0
        total_checks = 5

        # æ£€æŸ¥ä½¿ç”¨æŒ‡å¯¼
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if "ä½¿ç”¨æŒ‡å¯¼" in content or "å¿«é€Ÿå¼€å§‹" in content:
                score += 1
                break

        # æ£€æŸ¥ç¤ºä¾‹ä»£ç 
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if "```" in content:
                score += 1
                break

        # æ£€æŸ¥é”™è¯¯å¤„ç†è¯´æ˜
        for file_path in workflow_dir.glob("**/*"):
            if file_path.suffix in [".md", ".py", ".ps1"]:
                content = file_path.read_text(encoding="utf-8")
                if "é”™è¯¯" in content or "å¼‚å¸¸" in content or "æ•…éšœ" in content:
                    score += 1
                    break

        # æ£€æŸ¥é…ç½®è¯´æ˜
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if "é…ç½®" in content or "è®¾ç½®" in content:
                score += 1
                break

        # æ£€æŸ¥FAQæˆ–æ•…éšœæ’é™¤
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if "FAQ" in content or "æ•…éšœæ’é™¤" in content or "å¸¸è§é—®é¢˜" in content:
                score += 1
                break

        return (score / total_checks) * 10

    def _assess_maintainability(self, workflow_dir: Path) -> float:
        """è¯„ä¼°å¯ç»´æŠ¤æ€§"""
        score = 0.0
        total_checks = 4

        # æ£€æŸ¥ä»£ç æ³¨é‡Š
        python_files = list(workflow_dir.glob("**/*.py"))
        if python_files:
            total_lines = 0
            comment_lines = 0

            for py_file in python_files:
                content = py_file.read_text(encoding="utf-8")
                lines = content.split("\n")
                total_lines += len(lines)
                comment_lines += sum(
                    1 for line in lines if line.strip().startswith("#")
                )

            if total_lines > 0 and comment_lines / total_lines >= 0.1:
                score += 1

        # æ£€æŸ¥æ¨¡å—åŒ–è®¾è®¡
        if len(python_files) > 1:
            score += 1

        # æ£€æŸ¥ç‰ˆæœ¬æ§åˆ¶ä¿¡æ¯
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if "ç‰ˆæœ¬" in content or "version" in content.lower():
                score += 1
                break

        # æ£€æŸ¥æ—¥å¿—è®°å½•
        for py_file in workflow_dir.glob("**/*.py"):
            content = py_file.read_text(encoding="utf-8")
            if "logging" in content or "logger" in content:
                score += 1
                break

        return (score / total_checks) * 10

    def _assess_performance(self, workflow_dir: Path) -> float:
        """è¯„ä¼°æ€§èƒ½æ•ˆç‡"""
        score = 5.0  # é»˜è®¤ä¸­ç­‰åˆ†æ•°

        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„æ€§èƒ½åˆ†æé€»è¾‘
        # æ¯”å¦‚åˆ†æç®—æ³•å¤æ‚åº¦ã€å¹¶å‘å¤„ç†ç­‰

        return score

    def _assess_documentation(self, workflow_dir: Path) -> float:
        """è¯„ä¼°æ–‡æ¡£è´¨é‡"""
        score = 0.0
        total_checks = 4

        # æ£€æŸ¥READMEå­˜åœ¨
        if any(workflow_dir.glob("README.md")):
            score += 1

        # æ£€æŸ¥æ–‡æ¡£ç»“æ„å®Œæ•´æ€§
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if all(section in content for section in ["ç›®æ ‡", "ä½¿ç”¨", "æ­¥éª¤"]):
                score += 1
                break

        # æ£€æŸ¥ä»£ç æ–‡æ¡£
        for py_file in workflow_dir.glob("**/*.py"):
            content = py_file.read_text(encoding="utf-8")
            if '"""' in content or "def " in content:
                score += 1
                break

        # æ£€æŸ¥æ–‡æ¡£æ›´æ–°æ—¶é—´
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if "åˆ›å»ºæ—¶é—´" in content or "æ›´æ–°æ—¶é—´" in content:
                score += 1
                break

        return (score / total_checks) * 10

    def _assess_extensibility(self, workflow_dir: Path) -> float:
        """è¯„ä¼°æ‰©å±•æ€§"""
        score = 0.0
        total_checks = 3

        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        if any(workflow_dir.glob("**/*.json")) or any(workflow_dir.glob("**/*.yaml")):
            score += 1

        # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶
        if any(workflow_dir.glob("**/template*")):
            score += 1

        # æ£€æŸ¥æ’ä»¶æˆ–æ‰©å±•ç‚¹
        for py_file in workflow_dir.glob("**/*.py"):
            content = py_file.read_text(encoding="utf-8")
            if "plugin" in content.lower() or "extend" in content.lower():
                score += 1
                break

        return (score / total_checks) * 10

    def _generate_validation_report(self) -> Dict[str, Any]:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        total_syntax = (
            self.validation_results["syntax"]["passed"]
            + self.validation_results["syntax"]["failed"]
        )
        total_logic = (
            self.validation_results["logic"]["passed"]
            + self.validation_results["logic"]["failed"]
        )
        total_deps = (
            self.validation_results["dependencies"]["passed"]
            + self.validation_results["dependencies"]["failed"]
        )

        report = {
            "summary": {
                "overall_status": (
                    "PASS" if len(self._get_critical_issues()) == 0 else "FAIL"
                ),
                "total_issues": len(self._get_all_issues()),
                "critical_issues": len(self._get_critical_issues()),
                "quality_score": self.validation_results["quality"]["score"],
            },
            "syntax_validation": {
                "status": (
                    "PASS"
                    if self.validation_results["syntax"]["failed"] == 0
                    else "FAIL"
                ),
                "total_checks": total_syntax,
                "passed": self.validation_results["syntax"]["passed"],
                "failed": self.validation_results["syntax"]["failed"],
                "issues": self.validation_results["syntax"]["issues"],
            },
            "logic_validation": {
                "status": (
                    "PASS"
                    if self.validation_results["logic"]["failed"] == 0
                    else "FAIL"
                ),
                "total_checks": total_logic,
                "passed": self.validation_results["logic"]["passed"],
                "failed": self.validation_results["logic"]["failed"],
                "issues": self.validation_results["logic"]["issues"],
            },
            "dependency_validation": {
                "status": (
                    "PASS"
                    if self.validation_results["dependencies"]["failed"] == 0
                    else "FAIL"
                ),
                "total_checks": total_deps,
                "passed": self.validation_results["dependencies"]["passed"],
                "failed": self.validation_results["dependencies"]["failed"],
                "issues": self.validation_results["dependencies"]["issues"],
            },
            "quality_assessment": {
                "overall_score": self.validation_results["quality"]["score"],
                "grade": self._get_quality_grade(
                    self.validation_results["quality"]["score"]
                ),
                "details": self.validation_results["quality"]["details"],
            },
        }

        return report

    def _get_all_issues(self) -> List[Dict]:
        """è·å–æ‰€æœ‰é—®é¢˜"""
        all_issues = []
        all_issues.extend(self.validation_results["syntax"]["issues"])
        all_issues.extend(self.validation_results["logic"]["issues"])
        all_issues.extend(self.validation_results["dependencies"]["issues"])
        return all_issues

    def _get_critical_issues(self) -> List[Dict]:
        """è·å–å…³é”®é—®é¢˜"""
        critical_types = [
            "missing_main_workflow",
            "python_syntax",
            "missing_section",
            "broken_link",
        ]

        return [
            issue
            for issue in self._get_all_issues()
            if issue.get("type") in critical_types
        ]

    def _get_quality_grade(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 8.5:
            return "ä¼˜ç§€"
        elif score >= 7.0:
            return "è‰¯å¥½"
        elif score >= 6.0:
            return "åŠæ ¼"
        else:
            return "ä¸åŠæ ¼"


def main():
    """CLIå…¥å£å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="å·¥ä½œæµéªŒè¯å™¨")
    parser.add_argument("workflow_path", help="å·¥ä½œæµç›®å½•è·¯å¾„")
    parser.add_argument("--output", help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶")
    parser.add_argument(
        "--format", choices=["json", "text"], default="text", help="æŠ¥å‘Šæ ¼å¼"
    )

    args = parser.parse_args()

    # åˆ›å»ºéªŒè¯å™¨
    validator = WorkflowValidator()

    # æ‰§è¡ŒéªŒè¯
    report = validator.validate_workflow(args.workflow_path)

    # è¾“å‡ºæŠ¥å‘Š
    if args.format == "json":
        output = json.dumps(report, ensure_ascii=False, indent=2)
    else:
        output = _format_text_report(report)

    if args.output:
        with open(args.output, "w", encoding="utf-8") as f:
            f.write(output)
        print(f"âœ… éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: {args.output}")
    else:
        print(output)


def _format_text_report(report: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ–‡æœ¬æŠ¥å‘Š"""
    summary = report["summary"]

    output = f"""
# å·¥ä½œæµéªŒè¯æŠ¥å‘Š

## ğŸ“Š æ€»ä½“çŠ¶æ€
- **éªŒè¯çŠ¶æ€**: {summary["overall_status"]}
- **è´¨é‡è¯„åˆ†**: {summary["quality_score"]:.1f}/10.0 ({report["quality_assessment"]["grade"]})
- **é—®é¢˜æ€»æ•°**: {summary["total_issues"]}
- **å…³é”®é—®é¢˜**: {summary["critical_issues"]}

## ğŸ” è¯¦ç»†ç»“æœ

### è¯­æ³•éªŒè¯
- **çŠ¶æ€**: {report["syntax_validation"]["status"]}
- **é€šè¿‡**: {report["syntax_validation"]["passed"]}
- **å¤±è´¥**: {report["syntax_validation"]["failed"]}

### é€»è¾‘éªŒè¯
- **çŠ¶æ€**: {report["logic_validation"]["status"]}
- **é€šè¿‡**: {report["logic_validation"]["passed"]}
- **å¤±è´¥**: {report["logic_validation"]["failed"]}

### ä¾èµ–éªŒè¯
- **çŠ¶æ€**: {report["dependency_validation"]["status"]}
- **é€šè¿‡**: {report["dependency_validation"]["passed"]}
- **å¤±è´¥**: {report["dependency_validation"]["failed"]}

## ğŸ“ˆ è´¨é‡è¯„ä¼°è¯¦æƒ…
"""

    for dimension, score in report["quality_assessment"]["details"].items():
        output += f"- **{dimension}**: {score:.1f}/10.0\n"

    # æ·»åŠ é—®é¢˜è¯¦æƒ…
    all_issues = []
    all_issues.extend(report["syntax_validation"]["issues"])
    all_issues.extend(report["logic_validation"]["issues"])
    all_issues.extend(report["dependency_validation"]["issues"])

    if all_issues:
        output += "\n## âš ï¸ é—®é¢˜è¯¦æƒ…\n"
        for issue in all_issues:
            output += f"- **{issue['type']}**: {issue['message']}\n"
            if "file" in issue:
                output += f"  - æ–‡ä»¶: {issue['file']}\n"
            if "line" in issue:
                output += f"  - è¡Œå·: {issue['line']}\n"

    return output


if __name__ == "__main__":
    main()
