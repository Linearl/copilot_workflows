#!/usr/bin/env python3
"""
å·¥ä½œæµéªŒè¯å™¨ - è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„å·¥ä½œæµçš„è´¨é‡å’Œå®Œæ•´æ€§
æ”¯æŒè¯­æ³•æ£€æŸ¥ã€é€»è¾‘éªŒè¯ã€ä¾èµ–åˆ†æå’Œè´¨é‡è¯„ä¼°
å¢å¼ºç‰ˆï¼šæ”¯æŒæ’ä»¶ç³»ç»Ÿæ‰©å±•è¯„åˆ†ç»´åº¦

Author: Workflow Builder System
Version: 2.0.0
Last Updated: 2025-08-18

åŠŸèƒ½æ¦‚è¿°:
--------
è¿™ä¸ªéªŒè¯å™¨æä¾›äº†å®Œæ•´çš„å·¥ä½œæµè´¨é‡è¯„ä¼°ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š
1. è¯­æ³•éªŒè¯ï¼šæ£€æŸ¥Markdownã€Pythonã€PowerShellã€JSONæ–‡ä»¶çš„è¯­æ³•æ­£ç¡®æ€§
2. é€»è¾‘éªŒè¯ï¼šéªŒè¯å·¥ä½œæµçš„é€»è¾‘ä¸€è‡´æ€§å’Œå®Œæ•´æ€§
3. ä¾èµ–éªŒè¯ï¼šæ£€æŸ¥æ–‡ä»¶é—´çš„ä¾èµ–å…³ç³»å’Œå¼•ç”¨å®Œæ•´æ€§
4. è´¨é‡è¯„ä¼°ï¼šå¤šç»´åº¦è¯„ä¼°å·¥ä½œæµçš„è´¨é‡ï¼ˆæ”¯æŒæ’ä»¶æ‰©å±•ï¼‰

è¯¦ç»†è¯„åˆ†è§„åˆ™:
============

è´¨é‡è¯„ä¼°ç»´åº¦ (æ€»åˆ†10.0):
-----------------------

1. **Completeness (å®Œæ•´æ€§)** - æƒé‡30%
   - ä¸»è¦æ¨¡æ¿æ–‡ä»¶å­˜åœ¨ (+1.67åˆ†)
   - READMEæ–‡æ¡£å­˜åœ¨ (+1.67åˆ†)
   - å·¥å…·è„šæœ¬æ–‡ä»¶å­˜åœ¨ (+3.33åˆ†)
   - æ ¸å¿ƒæ–‡ä»¶å¤¹ç»“æ„å®Œæ•´ (+1.67åˆ†) - templates/docs/tools
   - æµ‹è¯•æ–‡ä»¶å­˜åœ¨ (+1.67åˆ†)
   - é…ç½®æ–‡ä»¶å­˜åœ¨ (+1.67åˆ†)

2. **Usability (æ˜“ç”¨æ€§)** - æƒé‡25%
   - ä½¿ç”¨æŒ‡å¯¼æ–‡æ¡£ (+2åˆ†)
   - ç¤ºä¾‹ä»£ç  (+2åˆ†)
   - é”™è¯¯å¤„ç†è¯´æ˜ (+2åˆ†)
   - é…ç½®è¯´æ˜ (+2åˆ†)
   - FAQæˆ–æ•…éšœæ’é™¤ (+2åˆ†)

3. **Maintainability (å¯ç»´æŠ¤æ€§)** - æƒé‡25%
   - ä»£ç æ³¨é‡Šç‡â‰¥10% (+2.5åˆ†)
   - é¢å‘å¯¹è±¡è®¾è®¡ (+2.5åˆ†) - ç±»å®šä¹‰ã€ç»§æ‰¿ã€æ–¹æ³•ã€è£…é¥°å™¨
   - ç‰ˆæœ¬æ§åˆ¶ä¿¡æ¯ (+2.5åˆ†)
   - æ—¥å¿—è®°å½•æœºåˆ¶ (+2.5åˆ†)

4. **Documentation (æ–‡æ¡£è´¨é‡)** - æƒé‡10%
   - READMEæ–‡ä»¶å­˜åœ¨ (+2.5åˆ†)
   - æ–‡æ¡£ç»“æ„å®Œæ•´æ€§ (+2.5åˆ†)
   - ä»£ç æ–‡æ¡£å­˜åœ¨ (+2.5åˆ†)
   - æ–‡æ¡£æ›´æ–°æ—¶é—´ (+2.5åˆ†)

5. **Extensibility (æ‰©å±•æ€§)** - æƒé‡10%
   - é…ç½®æ–‡ä»¶æ”¯æŒ (+3.33åˆ†)
   - æ¨¡æ¿æ–‡ä»¶ç³»ç»Ÿ (+3.33åˆ†)
   - æ’ä»¶æˆ–æ‰©å±•ç‚¹ (+3.33åˆ†)

æ’ä»¶ç³»ç»Ÿè¯„åˆ† (å¯é€‰):
------------------
å¦‚æœå¯ç”¨æ’ä»¶ç³»ç»Ÿï¼Œå¯ä»¥è¦†ç›–åŸæœ‰è¯„åˆ†ç»´åº¦ï¼š

- **Security Plugin**: å®‰å…¨æ€§è¯„ä¼° (0-10åˆ†)
  - æ— ç¡¬ç¼–ç æ•æ„Ÿä¿¡æ¯ (+2åˆ†)
  - .gitignoreæ–‡ä»¶å­˜åœ¨ (+2åˆ†)
  - æƒé™æ§åˆ¶é…ç½® (+2åˆ†)
  - è¾“å…¥éªŒè¯æœºåˆ¶ (+2åˆ†)
  - ä¾èµ–å®‰å…¨æ€§æ£€æŸ¥ (+2åˆ†)

- **Performance Plugin**: æ€§èƒ½è¯„ä¼° (0-10åˆ†)
  - æ€§èƒ½ä¼˜åŒ–ä»£ç  (+2.5åˆ†)
  - å¹¶å‘å¤„ç†æ”¯æŒ (+2.5åˆ†)
  - ç¼“å­˜æœºåˆ¶ (+2.5åˆ†)
  - èµ„æºç®¡ç† (+2.5åˆ†)

- **Test Coverage Plugin**: æµ‹è¯•è¦†ç›–ç‡è¯„ä¼° (0-10åˆ†)
  - æµ‹è¯•æ–‡ä»¶å­˜åœ¨ (+2.5åˆ†)
  - æµ‹è¯•è¦†ç›–ç‡è®¡ç®— (+2.5åˆ†)
  - æµ‹è¯•æ¡†æ¶ä½¿ç”¨ (+2.5åˆ†)
  - CIé…ç½®å­˜åœ¨ (+2.5åˆ†)

ä½¿ç”¨æ–¹æ³•:
========

åŸºç¡€ä½¿ç”¨:
--------
```python
from validator import WorkflowValidator

# åˆ›å»ºéªŒè¯å™¨å®ä¾‹
validator = WorkflowValidator(enable_plugins=True)

# éªŒè¯å·¥ä½œæµ
results = validator.validate_workflow("/path/to/workflow")

# è¾“å‡ºè´¨é‡å¾—åˆ†
print(f"è´¨é‡å¾—åˆ†: {results['summary']['quality_score']:.1f}/10.0")
print(f"ç­‰çº§: {results['quality_assessment']['grade']}")

# ç”ŸæˆæŠ¥å‘Š
report = validator.generate_report()
print(report)
```

å‘½ä»¤è¡Œä½¿ç”¨:
----------
```bash
# åŸºç¡€éªŒè¯
python validator.py /path/to/workflow

# æŒ‡å®šè¾“å‡ºæ–‡ä»¶
python validator.py /path/to/workflow --output report.txt

# JSONæ ¼å¼è¾“å‡º
python validator.py /path/to/workflow --format json

# æ’é™¤ç‰¹å®šæ–‡ä»¶
python validator.py /path/to/workflow --exclude "**/*.backup" --exclude "**/temp/**"
```

é«˜çº§é…ç½®:
--------
```python
# è‡ªå®šä¹‰æ’é™¤æ¨¡å¼
validator = WorkflowValidator(
    exclude_patterns=["**/private/**", "**/*.secret"],
    enable_plugins=True
)

# è·å–è¯¦ç»†çš„éªŒè¯ç»“æœ
results = validator.validate_workflow("/path/to/workflow")
for dimension, score in results['quality_assessment']['details'].items():
    print(f"{dimension}: {score:.1f}/10.0")
```

æ³¨æ„äº‹é¡¹:
--------
1. æ’ä»¶ç³»ç»Ÿéœ€è¦ validator_plugins.py å’Œ plugins_config.yaml
2. æ—¥å¿—æ–‡ä»¶ä¼šè¾“å‡ºåˆ° ../logs/validator.log
3. æŸäº›åŠŸèƒ½éœ€è¦ç³»ç»Ÿç¯å¢ƒæ”¯æŒï¼ˆå¦‚PowerShellè¯­æ³•æ£€æŸ¥ï¼‰
4. å¤§å‹é¡¹ç›®éªŒè¯å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
"""

import os
import re
import json
import subprocess
import sys
import argparse
import urllib.parse
import fnmatch
from pathlib import Path
from typing import Dict, List, Any, Tuple
import logging


# é…ç½®æ—¥å¿—ç³»ç»Ÿ
def setup_logging(log_level: str = "INFO") -> logging.Logger:
    """
    é…ç½®éªŒè¯å™¨æ—¥å¿—ç³»ç»Ÿ

    Args:
        log_level: æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR, CRITICAL)

    Returns:
        logging.Logger: é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """
    logger = logging.getLogger("workflow_validator")

    # é¿å…é‡å¤é…ç½®
    if logger.handlers:
        return logger

    logger.setLevel(getattr(logging, log_level.upper(), logging.INFO))

    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)

    # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨ï¼ˆå¦‚æœå¯èƒ½ï¼‰
    try:
        log_file = Path(__file__).parent.parent / "logs" / "validator.log"
        log_file.parent.mkdir(exist_ok=True)
        file_handler = logging.FileHandler(log_file, encoding="utf-8")
        file_handler.setLevel(logging.DEBUG)

        # è®¾ç½®æ ¼å¼
        detailed_formatter = logging.Formatter(
            "%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s"
        )
        file_handler.setFormatter(detailed_formatter)
        logger.addHandler(file_handler)
    except Exception as e:
        print(f"è­¦å‘Š: æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶: {e}")

    # ç®€åŒ–çš„æ§åˆ¶å°æ ¼å¼
    console_formatter = logging.Formatter("%(levelname)s: %(message)s")
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)

    return logger


# å°è¯•å¯¼å…¥æ’ä»¶ç³»ç»Ÿ
try:
    from .validator_plugins import PluginManager

    PLUGINS_AVAILABLE = True
except (ImportError, ModuleNotFoundError):
    try:
        from validator_plugins import PluginManager

        PLUGINS_AVAILABLE = True
    except (ImportError, ModuleNotFoundError):
        PLUGINS_AVAILABLE = False

# åˆå§‹åŒ–æ—¥å¿—
logger = setup_logging()


class WorkflowValidator:
    """
    å·¥ä½œæµéªŒè¯å™¨ä¸»ç±» - å¢å¼ºç‰ˆæ”¯æŒæ’ä»¶ç³»ç»Ÿ

    è¿™ä¸ªç±»æä¾›äº†å®Œæ•´çš„å·¥ä½œæµéªŒè¯åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - è¯­æ³•éªŒè¯ï¼šæ£€æŸ¥Markdownå’ŒPythonæ–‡ä»¶çš„è¯­æ³•æ­£ç¡®æ€§
    - é€»è¾‘éªŒè¯ï¼šéªŒè¯å·¥ä½œæµçš„é€»è¾‘ä¸€è‡´æ€§å’Œå®Œæ•´æ€§
    - ä¾èµ–éªŒè¯ï¼šæ£€æŸ¥æ–‡ä»¶é—´çš„ä¾èµ–å…³ç³»å’Œå¼•ç”¨å®Œæ•´æ€§
    - è´¨é‡è¯„ä¼°ï¼šå¤šç»´åº¦è¯„ä¼°å·¥ä½œæµçš„è´¨é‡ï¼ˆæ”¯æŒæ’ä»¶æ‰©å±•ï¼‰
    - æŠ¥å‘Šç”Ÿæˆï¼šç”Ÿæˆè¯¦ç»†çš„éªŒè¯æŠ¥å‘Š

    Attributes:
        validation_results (Dict): éªŒè¯ç»“æœå­˜å‚¨
        exclude_patterns (List[str]): éœ€è¦æ’é™¤çš„æ–‡ä»¶æ¨¡å¼
        enable_plugins (bool): æ˜¯å¦å¯ç”¨æ’ä»¶ç³»ç»Ÿ
        plugin_manager (PluginManager): æ’ä»¶ç®¡ç†å™¨å®ä¾‹

    Example:
        >>> validator = WorkflowValidator(enable_plugins=True)
        >>> results = validator.validate("/path/to/workflow")
        >>> print(validator.generate_report())
    """

    def __init__(self, exclude_patterns: List[str] = None, enable_plugins: bool = True):
        """
        åˆå§‹åŒ–å·¥ä½œæµéªŒè¯å™¨

        Args:
            exclude_patterns (List[str], optional): éœ€è¦æ’é™¤çš„æ–‡ä»¶æˆ–ç›®å½•æ¨¡å¼åˆ—è¡¨ï¼Œ
                ä¼šä¸é»˜è®¤æ’é™¤åˆ—è¡¨åˆå¹¶ã€‚æ”¯æŒglobæ¨¡å¼ï¼Œå¦‚ "**/*.backup"
            enable_plugins (bool, optional): æ˜¯å¦å¯ç”¨æ’ä»¶ç³»ç»Ÿè¿›è¡Œæ‰©å±•è¯„ä¼°ã€‚
                é»˜è®¤ä¸ºTrueï¼Œå¦‚æœæ’ä»¶ç³»ç»Ÿä¸å¯ç”¨ä¼šè‡ªåŠ¨é™çº§åˆ°æ ‡å‡†æ¨¡å¼

        Note:
            åˆå§‹åŒ–æ—¶ä¼šè‡ªåŠ¨è®¾ç½®æ—¥å¿—è®°å½•å’Œæ’ä»¶ç³»ç»Ÿï¼Œå¦‚æœæ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œ
            ä¼šè®°å½•è­¦å‘Šä¿¡æ¯ä½†ä¸ä¼šå½±å“åŸºç¡€éªŒè¯åŠŸèƒ½
        """
        logger.info("åˆå§‹åŒ–å·¥ä½œæµéªŒè¯å™¨")

        # åˆå§‹åŒ–éªŒè¯ç»“æœç»“æ„
        self.validation_results = {
            "syntax": {"passed": 0, "failed": 0, "issues": []},
            "logic": {"passed": 0, "failed": 0, "issues": []},
            "dependencies": {"passed": 0, "failed": 0, "issues": []},
            "quality": {"score": 0, "details": {}},
        }

        # é»˜è®¤æ’é™¤æ¨¡å¼
        default_patterns = [
            "**/workflow_system_analysis_report.md",
            "**/validation_*.txt",
            "**/*.backup*",
            "**/temp/**",
            "**/.git/**",
            "**/develop/**",
        ]

        # åˆå¹¶ç”¨æˆ·æä¾›çš„æ’é™¤æ¨¡å¼å’Œé»˜è®¤æ¨¡å¼
        if exclude_patterns:
            self.exclude_patterns = default_patterns + exclude_patterns
            logger.debug(f"ä½¿ç”¨è‡ªå®šä¹‰æ’é™¤æ¨¡å¼: {exclude_patterns}")
        else:
            self.exclude_patterns = default_patterns
        logger.debug(f"æœ€ç»ˆæ’é™¤æ¨¡å¼: {self.exclude_patterns}")

        # åˆå§‹åŒ–æ’ä»¶ç³»ç»Ÿ
        self.enable_plugins = enable_plugins and PLUGINS_AVAILABLE
        self.plugin_manager = None

        if self.enable_plugins:
            try:
                logger.info("å°è¯•åˆå§‹åŒ–æ’ä»¶ç³»ç»Ÿ")
                # æŸ¥æ‰¾æ’ä»¶é…ç½®æ–‡ä»¶
                current_dir = Path(__file__).parent.parent
                plugin_config_path = current_dir / "plugins_config.yaml"

                self.plugin_manager = PluginManager(plugin_config_path)
                logger.info(f"âœ… æ’ä»¶ç³»ç»Ÿå·²å¯ç”¨ï¼Œé…ç½®æ–‡ä»¶: {plugin_config_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ æ’ä»¶ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
                self.enable_plugins = False
        else:
            if not PLUGINS_AVAILABLE:
                logger.warning("æ’ä»¶ç³»ç»Ÿä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ ‡å‡†è¯„åˆ†æ¨¡å¼")
            else:
                logger.info("æ’ä»¶ç³»ç»Ÿå·²è¢«ç¦ç”¨")

        logger.info(
            f"éªŒè¯å™¨åˆå§‹åŒ–å®Œæˆ (æ’ä»¶ç³»ç»Ÿ: {'å¯ç”¨' if self.enable_plugins else 'ç¦ç”¨'})"
        )

    def _should_exclude_file(self, file_path: Path, base_path: Path) -> bool:
        """
        æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ’é™¤

        æ ¹æ®é…ç½®çš„æ’é™¤æ¨¡å¼ï¼ˆglob patternsï¼‰åˆ¤æ–­ç»™å®šæ–‡ä»¶æ˜¯å¦åº”è¯¥åœ¨éªŒè¯è¿‡ç¨‹ä¸­è¢«å¿½ç•¥ã€‚
        è¿™æœ‰åŠ©äºè·³è¿‡ä¸´æ—¶æ–‡ä»¶ã€å¤‡ä»½æ–‡ä»¶å’Œå…¶ä»–ä¸éœ€è¦éªŒè¯çš„æ–‡ä»¶ã€‚

        Args:
            file_path (Path): è¦æ£€æŸ¥çš„æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
            base_path (Path): åŸºç¡€è·¯å¾„ï¼Œç”¨äºè®¡ç®—ç›¸å¯¹è·¯å¾„è¿›è¡Œæ¨¡å¼åŒ¹é…

        Returns:
            bool: Trueè¡¨ç¤ºåº”è¯¥æ’é™¤è¯¥æ–‡ä»¶ï¼ŒFalseè¡¨ç¤ºåº”è¯¥åŒ…å«è¯¥æ–‡ä»¶è¿›è¡ŒéªŒè¯

        Example:
            >>> validator = WorkflowValidator()
            >>> should_exclude = validator._should_exclude_file(
            ...     Path("/project/.git/config"), Path("/project")
            ... )
            >>> print(should_exclude)  # True (git files are excluded by default)
        """
        try:
            # è®¡ç®—ç›¸å¯¹è·¯å¾„
            rel_path = file_path.relative_to(base_path)
            rel_path_str = str(rel_path).replace("\\", "/")

            # æ£€æŸ¥æ¯ä¸ªæ’é™¤æ¨¡å¼
            import fnmatch

            for pattern in self.exclude_patterns:
                # å¤„ç† ** é€šé…ç¬¦æ¨¡å¼
                if pattern.startswith("**/"):
                    # ç§»é™¤ **/ å‰ç¼€ï¼Œæ£€æŸ¥æ–‡ä»¶åæˆ–è·¯å¾„æœ«å°¾
                    simple_pattern = pattern[3:]

                    # å¦‚æœæ˜¯ç›®å½•æ¨¡å¼ (ä»¥ / ç»“å°¾æˆ–åŒ…å« / )
                    if simple_pattern.endswith("/") or "/" in simple_pattern:
                        # æå–ç›®å½•å
                        if simple_pattern.endswith("/"):
                            dir_name = simple_pattern.rstrip("/")
                        else:
                            # å¯¹äº develop/** è¿™æ ·çš„æ¨¡å¼ï¼Œæå–developéƒ¨åˆ†
                            dir_name = simple_pattern.split("/")[0]

                        # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨è¯¥ç›®å½•ä¸‹
                        path_parts = rel_path_str.split("/")
                        if dir_name in path_parts:
                            logger.debug(
                                f"æ’é™¤æ–‡ä»¶: {rel_path_str} (ç›®å½•åŒ¹é…: {pattern})"
                            )
                            return True
                    else:
                        # æ–‡ä»¶ååŒ¹é…
                        if fnmatch.fnmatch(
                            file_path.name, simple_pattern
                        ) or rel_path_str.endswith(simple_pattern):
                            logger.debug(
                                f"æ’é™¤æ–‡ä»¶: {rel_path_str} (åŒ¹é…æ¨¡å¼: {pattern})"
                            )
                            return True

                # æ™®é€šé€šé…ç¬¦åŒ¹é…
                elif fnmatch.fnmatch(rel_path_str, pattern):
                    logger.debug(f"æ’é™¤æ–‡ä»¶: {rel_path_str} (åŒ¹é…æ¨¡å¼: {pattern})")
                    return True
                # æ”¯æŒæ–‡ä»¶ååŒ¹é…
                elif fnmatch.fnmatch(file_path.name, pattern):
                    logger.debug(f"æ’é™¤æ–‡ä»¶: {rel_path_str} (æ–‡ä»¶ååŒ¹é…: {pattern})")
                    return True

            return False
        except ValueError:
            # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä¸æ’é™¤
            return False

    def validate_workflow(self, workflow_path: str) -> Dict[str, Any]:
        """
        å…¨é¢éªŒè¯å·¥ä½œæµ

        å¯¹æŒ‡å®šçš„å·¥ä½œæµç›®å½•æ‰§è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹ï¼ŒåŒ…æ‹¬è¯­æ³•éªŒè¯ã€é€»è¾‘éªŒè¯ã€
        ä¾èµ–éªŒè¯å’Œè´¨é‡è¯„ä¼°ã€‚è¿™æ˜¯éªŒè¯å™¨çš„ä¸»è¦å…¥å£æ–¹æ³•ã€‚

        Args:
            workflow_path (str): å·¥ä½œæµç›®å½•çš„ç»å¯¹è·¯å¾„

        Returns:
            Dict[str, Any]: åŒ…å«æ‰€æœ‰éªŒè¯ç»“æœçš„å­—å…¸ï¼Œç»“æ„å¦‚ä¸‹ï¼š
                {
                    "overall_status": "PASS"/"FAIL",
                    "total_issues": int,
                    "critical_issues": int,
                    "quality_score": float,
                    "validation_results": {...}
                }

        Raises:
            FileNotFoundError: å¦‚æœå·¥ä½œæµè·¯å¾„ä¸å­˜åœ¨
            PermissionError: å¦‚æœæ²¡æœ‰è¯»å–æƒé™

        Example:
            >>> validator = WorkflowValidator()
            >>> results = validator.validate_workflow("/path/to/workflow")
            >>> print(f"è´¨é‡å¾—åˆ†: {results['quality_score']}")
        """
        logger.info(f"å¼€å§‹éªŒè¯å·¥ä½œæµ: {workflow_path}")

        # éªŒè¯è·¯å¾„å­˜åœ¨
        workflow_dir = Path(workflow_path)
        if not workflow_dir.exists():
            raise FileNotFoundError(f"å·¥ä½œæµè·¯å¾„ä¸å­˜åœ¨: {workflow_path}")
        if not workflow_dir.is_dir():
            raise NotADirectoryError(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {workflow_path}")

        start_time = logger.debug("éªŒè¯å¼€å§‹")
        logger.info(f"å¼€å§‹éªŒè¯å·¥ä½œæµ: {workflow_path}")

        workflow_dir = Path(workflow_path)
        if not workflow_dir.exists():
            raise FileNotFoundError(f"å·¥ä½œæµè·¯å¾„ä¸å­˜åœ¨: {workflow_path}")

        # é‡ç½®éªŒè¯ç»“æœ
        self._reset_results()

        # è¯­æ³•éªŒè¯
        self.validate_syntax(workflow_path)

        # é€»è¾‘éªŒè¯
        self.validate_logic(workflow_path)

        # ä¾èµ–éªŒè¯
        self.validate_dependencies(workflow_path)

        # è´¨é‡è¯„ä¼°
        self.assess_quality(workflow_path)

        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = self._generate_validation_report()

        logger.info("å·¥ä½œæµéªŒè¯å®Œæˆ")
        return report

    def _reset_results(self):
        """é‡ç½®éªŒè¯ç»“æœ"""
        self.validation_results = {
            "syntax": {"passed": 0, "failed": 0, "issues": []},
            "logic": {"passed": 0, "failed": 0, "issues": []},
            "dependencies": {"passed": 0, "failed": 0, "issues": []},
            "quality": {"score": 0, "details": {}},
        }

    def validate_syntax(self, workflow_path: str):
        """éªŒè¯è¯­æ³•æ­£ç¡®æ€§"""
        logger.info("æ‰§è¡Œè¯­æ³•éªŒè¯")

        workflow_dir = Path(workflow_path)

        # éªŒè¯Markdownæ–‡ä»¶
        for md_file in workflow_dir.glob("**/*.md"):
            if not self._should_exclude_file(md_file, workflow_dir):
                self._validate_markdown_syntax(md_file)

        # éªŒè¯Pythonè„šæœ¬
        for py_file in workflow_dir.glob("**/*.py"):
            if not self._should_exclude_file(py_file, workflow_dir):
                self._validate_python_syntax(py_file)

        # éªŒè¯PowerShellè„šæœ¬
        for ps_file in workflow_dir.glob("**/*.ps1"):
            if not self._should_exclude_file(ps_file, workflow_dir):
                self._validate_powershell_syntax(ps_file)

        # éªŒè¯JSONæ–‡ä»¶
        for json_file in workflow_dir.glob("**/*.json"):
            if not self._should_exclude_file(json_file, workflow_dir):
                self._validate_json_syntax(json_file)

    def _validate_markdown_syntax(self, file_path: Path):
        """
        éªŒè¯Markdownæ–‡ä»¶çš„è¯­æ³•æ­£ç¡®æ€§

        å¯¹æŒ‡å®šçš„Markdownæ–‡ä»¶æ‰§è¡Œå¤šé¡¹è¯­æ³•å’Œæ ¼å¼æ£€æŸ¥ï¼ŒåŒ…æ‹¬æ ‡é¢˜å±‚æ¬¡ç»“æ„ã€
        é“¾æ¥å®Œæ•´æ€§ã€ä»£ç å—æ ¼å¼ç­‰ã€‚æ£€æŸ¥ç»“æœä¼šè®°å½•åˆ°validation_resultsä¸­ã€‚

        Args:
            file_path (Path): è¦éªŒè¯çš„Markdownæ–‡ä»¶è·¯å¾„

        Returns:
            None: æ£€æŸ¥ç»“æœé€šè¿‡validation_resultså±æ€§è®¿é—®

        Raises:
            Exception: æ–‡ä»¶è¯»å–æˆ–è§£æå¤±è´¥æ—¶ä¼šæ•è·å¼‚å¸¸å¹¶è®°å½•åˆ°issuesä¸­

        æ£€æŸ¥é¡¹ç›®:
        --------
        1. æ ‡é¢˜å±‚æ¬¡ç»“æ„ - ç¡®ä¿æ ‡é¢˜çº§åˆ«ä¸è·³è·ƒ
        2. é“¾æ¥å®Œæ•´æ€§ - éªŒè¯å†…éƒ¨å’Œå¤–éƒ¨é“¾æ¥çš„æœ‰æ•ˆæ€§
        3. ä»£ç å—æ ¼å¼ - æ£€æŸ¥ä»£ç å—æ˜¯å¦æœ‰è¯­è¨€æ ‡è¯†
        4. åˆ—è¡¨æ ¼å¼ - éªŒè¯åˆ—è¡¨æ ¼å¼è§„èŒƒï¼ˆå·²ç¦ç”¨ï¼‰

        Note:
            å¿½ç•¥ä»£ç å—å†…çš„å†…å®¹ï¼Œé¿å…è¯¯æŠ¥æ ‡é¢˜å’Œé“¾æ¥é—®é¢˜
        """
        try:
            content = file_path.read_text(encoding="utf-8")

            # æ£€æŸ¥æ ‡é¢˜å±‚æ¬¡
            self._check_heading_hierarchy(content, file_path)

            # æ£€æŸ¥é“¾æ¥å®Œæ•´æ€§
            self._check_link_integrity(content, file_path)

            # æ£€æŸ¥ä»£ç å—æ ¼å¼
            self._check_code_block_format(content, file_path)

            # æ£€æŸ¥åˆ—è¡¨æ ¼å¼ - å·²ç¦ç”¨ï¼Œå› ä¸ºå®é™…æ¸²æŸ“æ­£å¸¸ä¸”ä¸å½±å“åŠŸèƒ½
            # self._check_list_format(content, file_path)

            self.validation_results["syntax"]["passed"] += 1

        except Exception as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "markdown_syntax",
                    "message": f"Markdownè¯­æ³•é”™è¯¯: {str(e)}",
                }
            )

    def _check_heading_hierarchy(self, content: str, file_path: Path):
        """
        æ£€æŸ¥Markdownæ ‡é¢˜å±‚æ¬¡ç»“æ„çš„æ­£ç¡®æ€§

        éªŒè¯Markdownæ–‡ä»¶ä¸­çš„æ ‡é¢˜å±‚æ¬¡æ˜¯å¦ç¬¦åˆè§„èŒƒï¼Œå³ä¸åº”è¯¥å‡ºç°çº§åˆ«è·³è·ƒ
        ï¼ˆå¦‚ä»H1ç›´æ¥è·³åˆ°H3ï¼‰ã€‚ä¼šå¿½ç•¥ä»£ç å—å†…çš„å†…å®¹ä»¥é¿å…è¯¯æŠ¥ã€‚

        Args:
            content (str): Markdownæ–‡ä»¶çš„æ–‡æœ¬å†…å®¹
            file_path (Path): æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºé”™è¯¯æŠ¥å‘Š

        Returns:
            None: æ£€æŸ¥ç»“æœé€šè¿‡validation_resultså±æ€§è®¿é—®

        æ£€æŸ¥è§„åˆ™:
        --------
        1. æ ‡é¢˜å¿…é¡»ä»¥#å¼€å¤´ä¸”åé¢æœ‰ç©ºæ ¼æ‰è¢«è®¤ä¸ºæ˜¯æœ‰æ•ˆæ ‡é¢˜
        2. ä¸èƒ½æœ‰çº§åˆ«è·³è·ƒï¼šH1->H3ã€H2->H4ç­‰éƒ½æ˜¯ä¸å…è®¸çš„
        3. å¿½ç•¥ä»£ç å—å†…çš„#ç¬¦å·
        4. å¿½ç•¥HTMLæ³¨é‡Šå†…çš„å†…å®¹

        é”™è¯¯ç±»å‹:
        --------
        - heading_hierarchy: æ ‡é¢˜å±‚æ¬¡è·³è·ƒé”™è¯¯

        Example:
            æ­£ç¡®: # H1 -> ## H2 -> ### H3
            é”™è¯¯: # H1 -> ### H3 (è·³è¿‡äº†H2)
        """
        lines = content.split("\n")
        prev_level = 0
        in_code_block = False

        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥æ˜¯å¦è¿›å…¥æˆ–é€€å‡ºä»£ç å—
            if line.strip().startswith("```"):
                in_code_block = not in_code_block
                continue

            # å¿½ç•¥ä»£ç å—å†…çš„è¡Œ
            if in_code_block:
                continue

            # æ£€æŸ¥çœŸæ­£çš„markdownæ ‡é¢˜
            if line.startswith("#") and " " in line:  # å¿…é¡»æœ‰ç©ºæ ¼æ‰æ˜¯æœ‰æ•ˆæ ‡é¢˜
                level = len(line) - len(line.lstrip("#"))

                # æ£€æŸ¥å±‚æ¬¡è·³è·ƒ
                if level > prev_level + 1:
                    self.validation_results["syntax"]["issues"].append(
                        {
                            "file": str(file_path),
                            "line": i,
                            "type": "heading_hierarchy",
                            "message": f"æ ‡é¢˜å±‚æ¬¡è·³è·ƒ: ä» H{prev_level} ç›´æ¥è·³åˆ° H{level}",
                        }
                    )

                prev_level = level

    def _check_link_integrity(self, content: str, file_path: Path):
        """æ£€æŸ¥é“¾æ¥å®Œæ•´æ€§ - æ”¯æŒæ›´å®½æ¾çš„emoji anchoråŒ¹é…"""
        # æ£€æŸ¥å†…éƒ¨é“¾æ¥
        internal_links = re.findall(r"\[([^\]]+)\]\(#([^)]+)\)", content)

        # æå–æ‰€æœ‰æ ‡é¢˜é”šç‚¹ï¼Œç”Ÿæˆå¤šç§å¯èƒ½çš„æ ¼å¼
        anchors = set()
        for line in content.split("\n"):
            if line.startswith("#"):
                title = line.lstrip("# ").strip()
                # ç”Ÿæˆå¤šç§å¯èƒ½çš„anchoræ ¼å¼
                possible_anchors = self._generate_possible_anchors(title)
                anchors.update(possible_anchors)

        # éªŒè¯å†…éƒ¨é“¾æ¥ - ä½¿ç”¨å®½æ¾åŒ¹é…
        for link_text, anchor in internal_links:
            if not self._is_anchor_valid(anchor, anchors):
                self.validation_results["syntax"]["issues"].append(
                    {
                        "file": str(file_path),
                        "type": "broken_link",
                        "message": f"æ–­å¼€çš„å†…éƒ¨é“¾æ¥: [{link_text}](#{anchor})",
                    }
                )

        # æ£€æŸ¥å¤–éƒ¨æ–‡ä»¶é“¾æ¥
        file_links = re.findall(r"\[([^\]]+)\]\(([^#)]+\.md[^)]*)\)", content)
        for link_text, file_link in file_links:
            # åˆ†ç¦»æ–‡ä»¶è·¯å¾„å’Œanchor
            if "#" in file_link:
                file_path_part, anchor_part = file_link.split("#", 1)
                target_file = file_path.parent / file_path_part
                if target_file.exists():
                    # æ£€æŸ¥targetæ–‡ä»¶ä¸­çš„anchor
                    if not self._check_external_anchor(target_file, anchor_part):
                        self.validation_results["syntax"]["issues"].append(
                            {
                                "file": str(file_path),
                                "type": "broken_file_link",
                                "message": f"æ–­å¼€çš„æ–‡ä»¶é“¾æ¥: [{link_text}]({file_link})",
                            }
                        )
                else:
                    self.validation_results["syntax"]["issues"].append(
                        {
                            "file": str(file_path),
                            "type": "broken_file_link",
                            "message": f"æ–­å¼€çš„æ–‡ä»¶é“¾æ¥: [{link_text}]({file_link})",
                        }
                    )
            else:
                target_file = file_path.parent / file_link
                if not target_file.exists():
                    self.validation_results["syntax"]["issues"].append(
                        {
                            "file": str(file_path),
                            "type": "broken_file_link",
                            "message": f"æ–­å¼€çš„æ–‡ä»¶é“¾æ¥: [{link_text}]({file_link})",
                        }
                    )

    def _generate_possible_anchors(self, title: str) -> list:
        """ç”Ÿæˆæ ‡é¢˜çš„å¤šç§å¯èƒ½anchoræ ¼å¼"""
        title = title.lstrip("# ").strip()
        anchors = []

        # æ ¼å¼1: æ ‡å‡†æ ¼å¼ - ç©ºæ ¼è½¬è¿å­—ç¬¦ï¼Œç§»é™¤æ ‡ç‚¹
        anchor1 = re.sub(r"\s+", "-", title)
        anchor1 = re.sub(r'[ï¼šï¼›\'".,!?()]', "", anchor1)
        anchor1 = re.sub(r"-+", "-", anchor1).strip("-")
        anchors.append(anchor1)
        anchors.append(anchor1.lower())

        # æ ¼å¼2: ç§»é™¤æ‹¬å·å†…å®¹åå¤„ç†
        title_no_parens = re.sub(r"\s*\([^)]*\)", "", title).strip()
        if title_no_parens != title:
            anchor2 = re.sub(r"\s+", "-", title_no_parens)
            anchor2 = re.sub(r'[ï¼šï¼›\'".,!?()]', "", anchor2)
            anchor2 = re.sub(r"-+", "-", anchor2).strip("-")
            anchors.append(anchor2)
            anchors.append(anchor2.lower())

        # æ ¼å¼3: GitHubé£æ ¼ - å…¨éƒ¨è½¬å°å†™ï¼Œç‰¹æ®Šå¤„ç†
        github_anchor = title.lower()
        github_anchor = re.sub(
            r"[^\w\s\u4e00-\u9fff\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF-]",
            "",
            github_anchor,
        )
        github_anchor = re.sub(r"\s+", "-", github_anchor)
        github_anchor = re.sub(r"-+", "-", github_anchor).strip("-")
        if github_anchor:
            anchors.append(github_anchor)

        # æ ¼å¼4: Typoraé£æ ¼ - ä¿ç•™emojiï¼Œæ‹¬å·å†…å®¹ç”¨è¿å­—ç¬¦
        typora_anchor = re.sub(r"\s*\(([^)]*)\)", r"-\1", title)
        typora_anchor = re.sub(r"\s+", "-", typora_anchor)
        typora_anchor = re.sub(r'[ï¼šï¼›\'".,!?]', "", typora_anchor)
        typora_anchor = re.sub(r"-+", "-", typora_anchor).strip("-")
        anchors.append(typora_anchor)
        anchors.append(typora_anchor.lower())

        # æ ¼å¼5: ç®€åŒ–ç‰ˆæœ¬ - ä»…ä¿ç•™ä¸»è¦å†…å®¹
        simple_title = re.sub(
            r"[^\w\s\u4e00-\u9fff\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]",
            "",
            title,
        )
        simple_anchor = re.sub(r"\s+", "-", simple_title.strip())
        if simple_anchor:
            anchors.append(simple_anchor)
            anchors.append(simple_anchor.lower())

        return list(set(filter(None, anchors)))  # å»é‡å¹¶ç§»é™¤ç©ºå€¼

    def _is_anchor_valid(self, anchor: str, valid_anchors: set) -> bool:
        """æ£€æŸ¥anchoræ˜¯å¦æœ‰æ•ˆ - æ”¯æŒå®½æ¾åŒ¹é…"""
        if anchor in valid_anchors:
            return True

        # å°è¯•URLè§£ç 
        try:
            import urllib.parse

            decoded_anchor = urllib.parse.unquote(anchor)
            if decoded_anchor in valid_anchors:
                return True
        except:
            pass

        # å®½æ¾åŒ¹é…ï¼šå¿½ç•¥å¤§å°å†™å’Œä¸€äº›ç‰¹æ®Šå­—ç¬¦å·®å¼‚
        normalized_anchor = anchor.lower().strip("-")
        for valid_anchor in valid_anchors:
            if normalized_anchor == valid_anchor.lower().strip("-"):
                return True

        return False

    def _check_external_anchor(self, target_file: Path, anchor: str) -> bool:
        """æ£€æŸ¥å¤–éƒ¨æ–‡ä»¶ä¸­çš„anchoræ˜¯å¦å­˜åœ¨"""
        try:
            content = target_file.read_text(encoding="utf-8")
            anchors = set()
            for line in content.split("\n"):
                if line.startswith("#"):
                    title = line.lstrip("# ").strip()
                    possible_anchors = self._generate_possible_anchors(title)
                    anchors.update(possible_anchors)
            return self._is_anchor_valid(anchor, anchors)
        except:
            return False

    def _generate_anchor(self, title: str) -> str:
        """ç”Ÿæˆæ ‡é¢˜é”šç‚¹ - æ”¯æŒemojiæ ¼å¼"""
        # ç§»é™¤markdownæ ‡é¢˜æ ‡è®°
        anchor = title.lstrip("# ").strip()

        # å¯¹äºåŒ…å«emojiçš„æ ‡é¢˜ï¼Œé‡‡ç”¨Typoraå…¼å®¹æ ¼å¼
        # æ ¹æ®æ‚¨çš„ç¤ºä¾‹: [ğŸ“ å‡†å¤‡é˜¶æ®µ (Preparation Phase)](#ğŸ“-å‡†å¤‡é˜¶æ®µ-preparation-phase)
        # é”šç‚¹æ ¼å¼åº”è¯¥æ˜¯: emoji-åç»­æ–‡å­—-ç”¨è¿å­—ç¬¦è¿æ¥

        # ä¸è½¬æ¢ä¸ºå°å†™ï¼Œä¿æŒåŸå§‹å¤§å°å†™ï¼ˆé™¤äº†è¿å­—ç¬¦åŒ–ï¼‰

        # å°†ç©ºæ ¼æ›¿æ¢ä¸ºè¿å­—ç¬¦ï¼Œä½†ä¿ç•™emojiå’Œä¸­æ–‡å­—ç¬¦
        anchor = re.sub(r"\s+", "-", anchor)

        # ç§»é™¤ä¸éœ€è¦çš„ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™emojiã€ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€è¿å­—ç¬¦ã€æ‹¬å·
        # æ”¯æŒæ›´å¤šemojiå­—ç¬¦
        anchor = re.sub(r'[ï¼šï¼›\'".,!?]', "", anchor)

        # æ¸…ç†å¤šä½™çš„è¿å­—ç¬¦
        anchor = re.sub(r"-+", "-", anchor)
        anchor = anchor.strip("-")

        return anchor

    def _check_code_block_format(self, content: str, file_path: Path):
        """æ£€æŸ¥ä»£ç å—æ ¼å¼"""
        lines = content.split("\n")
        in_code_block = False

        for i, line in enumerate(lines, 1):
            if line.startswith("```"):
                if not in_code_block:
                    # å¼€å§‹ä»£ç å—
                    if line.strip() == "```":
                        self.validation_results["syntax"]["issues"].append(
                            {
                                "file": str(file_path),
                                "line": i,
                                "type": "code_block_language",
                                "message": "ä»£ç å—ç¼ºå°‘è¯­è¨€æ ‡è¯†",
                            }
                        )
                    in_code_block = True
                else:
                    # ç»“æŸä»£ç å—
                    in_code_block = False

    def _check_list_format(self, content: str, file_path: Path):
        """æ£€æŸ¥åˆ—è¡¨æ ¼å¼"""
        lines = content.split("\n")

        for i, line in enumerate(lines, 1):
            if re.match(r"^[\s]*[-*+]\s", line):
                # æ£€æŸ¥å‰åç©ºè¡Œ
                if (
                    i > 1
                    and lines[i - 2].strip() != ""
                    and not re.match(r"^[\s]*[-*+]\s", lines[i - 2])
                ):
                    self.validation_results["syntax"]["issues"].append(
                        {
                            "file": str(file_path),
                            "line": i,
                            "type": "list_format",
                            "message": "åˆ—è¡¨å‰éœ€è¦ç©ºè¡Œ",
                        }
                    )

    def _validate_python_syntax(self, file_path: Path):
        """éªŒè¯Pythonè¯­æ³•"""
        try:
            content = file_path.read_text(encoding="utf-8")
            compile(content, str(file_path), "exec")
            self.validation_results["syntax"]["passed"] += 1

        except SyntaxError as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "line": e.lineno,
                    "type": "python_syntax",
                    "message": f"Pythonè¯­æ³•é”™è¯¯: {e.msg}",
                }
            )
        except Exception as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "python_error",
                    "message": f"Pythonæ–‡ä»¶é”™è¯¯: {str(e)}",
                }
            )

    def _validate_powershell_syntax(self, file_path: Path):
        """éªŒè¯PowerShellè¯­æ³•"""
        try:
            # ä½¿ç”¨PowerShellæ£€æŸ¥è¯­æ³•
            result = subprocess.run(
                [
                    "powershell",
                    "-Command",
                    f'$null = Get-Content "{file_path}" | Out-String | Invoke-Expression',
                ],
                capture_output=True,
                text=True,
                timeout=10,
            )

            if result.returncode == 0:
                self.validation_results["syntax"]["passed"] += 1
            else:
                self.validation_results["syntax"]["failed"] += 1
                self.validation_results["syntax"]["issues"].append(
                    {
                        "file": str(file_path),
                        "type": "powershell_syntax",
                        "message": f"PowerShellè¯­æ³•é”™è¯¯: {result.stderr}",
                    }
                )

        except subprocess.TimeoutExpired:
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "powershell_timeout",
                    "message": "PowerShellè¯­æ³•æ£€æŸ¥è¶…æ—¶",
                }
            )
        except Exception as e:
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "type": "powershell_error",
                    "message": f"PowerShellæ£€æŸ¥é”™è¯¯: {str(e)}",
                }
            )

    def _validate_json_syntax(self, file_path: Path):
        """éªŒè¯JSONè¯­æ³•"""
        try:
            content = file_path.read_text(encoding="utf-8")
            json.loads(content)
            self.validation_results["syntax"]["passed"] += 1

        except json.JSONDecodeError as e:
            self.validation_results["syntax"]["failed"] += 1
            self.validation_results["syntax"]["issues"].append(
                {
                    "file": str(file_path),
                    "line": e.lineno,
                    "type": "json_syntax",
                    "message": f"JSONè¯­æ³•é”™è¯¯: {e.msg}",
                }
            )

    def validate_logic(self, workflow_path: str):
        """éªŒè¯é€»è¾‘å®Œæ•´æ€§"""
        logger.info("æ‰§è¡Œé€»è¾‘éªŒè¯")

        workflow_dir = Path(workflow_path)

        # æŸ¥æ‰¾ä¸»å·¥ä½œæµæ–‡ä»¶
        main_workflow = self._find_main_workflow(workflow_dir)
        if not main_workflow:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {"type": "missing_main_workflow", "message": "æœªæ‰¾åˆ°ä¸»å·¥ä½œæµæ–‡ä»¶"}
            )
            return

        # éªŒè¯å·¥ä½œæµç»“æ„
        self._validate_workflow_structure(main_workflow)

        # éªŒè¯æ­¥éª¤å®Œæ•´æ€§
        self._validate_step_completeness(main_workflow)

        # éªŒè¯ç¡®è®¤æ£€æŸ¥ç‚¹
        self._validate_checkpoints(main_workflow)

        # éªŒè¯æ–‡ä»¶å¼•ç”¨
        self._validate_file_references(main_workflow, workflow_dir)

    def _find_main_workflow(self, workflow_dir: Path) -> Path:
        """æŸ¥æ‰¾ä¸»å·¥ä½œæµæ–‡ä»¶"""
        # æŸ¥æ‰¾æ¨¡æ¿æ–‡ä»¶
        templates = list(workflow_dir.glob("*_template.md"))
        if templates:
            return templates[0]

        # æŸ¥æ‰¾workflow.md
        workflow_md = workflow_dir / "workflow.md"
        if workflow_md.exists():
            return workflow_md

        # æŸ¥æ‰¾README.md
        readme_md = workflow_dir / "README.md"
        if readme_md.exists():
            return readme_md

        return None

    def _validate_workflow_structure(self, workflow_file: Path):
        """éªŒè¯å·¥ä½œæµç»“æ„"""
        content = workflow_file.read_text(encoding="utf-8")

        required_sections = ["å·¥ä½œæµç®€ä»‹", "ç›®å½•ç»“æ„", "æ ‡å‡†æµç¨‹", "è‡ªåŠ¨ç”ŸæˆåŒºåŸŸ"]

        for section in required_sections:
            if section not in content:
                self.validation_results["logic"]["failed"] += 1
                self.validation_results["logic"]["issues"].append(
                    {
                        "file": str(workflow_file),
                        "type": "missing_section",
                        "message": f"ç¼ºå°‘å¿…éœ€ç« èŠ‚: {section}",
                    }
                )
            else:
                self.validation_results["logic"]["passed"] += 1

    def _validate_step_completeness(self, workflow_file: Path):
        """éªŒè¯æ­¥éª¤å®Œæ•´æ€§"""
        content = workflow_file.read_text(encoding="utf-8")

        # æŸ¥æ‰¾æ­¥éª¤å®šä¹‰
        steps = re.findall(r"### æ­¥éª¤(\d+)ï¼š(.+)", content)

        if not steps:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {
                    "file": str(workflow_file),
                    "type": "no_steps",
                    "message": "æœªæ‰¾åˆ°å·¥ä½œæµæ­¥éª¤å®šä¹‰",
                }
            )
            return

        # æ£€æŸ¥æ­¥éª¤è¿ç»­æ€§
        step_numbers = [int(step[0]) for step in steps]
        expected_numbers = list(range(1, len(step_numbers) + 1))

        if step_numbers != expected_numbers:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {
                    "file": str(workflow_file),
                    "type": "step_numbering",
                    "message": f"æ­¥éª¤ç¼–å·ä¸è¿ç»­: {step_numbers}",
                }
            )
        else:
            self.validation_results["logic"]["passed"] += 1

    def _validate_checkpoints(self, workflow_file: Path):
        """éªŒè¯ç¡®è®¤æ£€æŸ¥ç‚¹"""
        content = workflow_file.read_text(encoding="utf-8")

        # æŸ¥æ‰¾ç¡®è®¤æ£€æŸ¥ç‚¹
        checkpoints = re.findall(r"ğŸ¤.*?ç”¨æˆ·ç¡®è®¤æ£€æŸ¥ç‚¹", content)

        if len(checkpoints) < 2:
            self.validation_results["logic"]["failed"] += 1
            self.validation_results["logic"]["issues"].append(
                {
                    "file": str(workflow_file),
                    "type": "insufficient_checkpoints",
                    "message": f"ç¡®è®¤æ£€æŸ¥ç‚¹ä¸è¶³: æ‰¾åˆ°{len(checkpoints)}ä¸ªï¼Œå»ºè®®è‡³å°‘2ä¸ª",
                }
            )
        else:
            self.validation_results["logic"]["passed"] += 1

    def _validate_file_references(self, workflow_file: Path, workflow_dir: Path):
        """éªŒè¯æ–‡ä»¶å¼•ç”¨"""
        content = workflow_file.read_text(encoding="utf-8")

        # æŸ¥æ‰¾è„šæœ¬å¼•ç”¨
        script_refs = re.findall(r"`([^`]+\.(py|ps1|sh))`", content)

        for script_ref, ext in script_refs:
            script_path = workflow_dir / script_ref
            if not script_path.exists():
                self.validation_results["logic"]["failed"] += 1
                self.validation_results["logic"]["issues"].append(
                    {
                        "file": str(workflow_file),
                        "type": "missing_script",
                        "message": f"å¼•ç”¨çš„è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨: {script_ref}",
                    }
                )
            else:
                self.validation_results["logic"]["passed"] += 1

    def validate_dependencies(self, workflow_path: str):
        """éªŒè¯ä¾èµ–å®Œæ•´æ€§"""
        logger.info("æ‰§è¡Œä¾èµ–éªŒè¯")

        workflow_dir = Path(workflow_path)

        # æ£€æŸ¥Pythonä¾èµ–
        self._check_python_dependencies(workflow_dir)

        # æ£€æŸ¥PowerShellæ¨¡å—
        self._check_powershell_modules(workflow_dir)

        # æ£€æŸ¥ç³»ç»Ÿä¾èµ–
        self._check_system_dependencies(workflow_dir)

    def _check_python_dependencies(self, workflow_dir: Path):
        """æ£€æŸ¥Pythonä¾èµ–"""
        requirements_file = workflow_dir / "requirements.txt"

        if requirements_file.exists():
            try:
                content = requirements_file.read_text(encoding="utf-8")
                packages = [
                    line.strip() for line in content.split("\n") if line.strip()
                ]

                for package in packages:
                    # éªŒè¯åŒ…åæ ¼å¼
                    if not re.match(r"^[a-zA-Z0-9-_]+([>=<]=?[\d.]+)?$", package):
                        self.validation_results["dependencies"]["failed"] += 1
                        self.validation_results["dependencies"]["issues"].append(
                            {
                                "file": str(requirements_file),
                                "type": "invalid_package",
                                "message": f"æ— æ•ˆçš„åŒ…åæ ¼å¼: {package}",
                            }
                        )
                    else:
                        self.validation_results["dependencies"]["passed"] += 1

            except Exception as e:
                self.validation_results["dependencies"]["failed"] += 1
                self.validation_results["dependencies"]["issues"].append(
                    {
                        "file": str(requirements_file),
                        "type": "requirements_error",
                        "message": f"requirements.txtè¯»å–é”™è¯¯: {str(e)}",
                    }
                )

        # æ£€æŸ¥Pythonè„šæœ¬ä¸­çš„import
        for py_file in workflow_dir.glob("**/*.py"):
            self._check_python_imports(py_file)

    def _check_python_imports(self, py_file: Path):
        """æ£€æŸ¥Pythonå¯¼å…¥"""
        try:
            content = py_file.read_text(encoding="utf-8")
            imports = re.findall(
                r"^(?:from\s+(\w+)|import\s+(\w+))", content, re.MULTILINE
            )

            for from_import, direct_import in imports:
                module = from_import or direct_import
                if module and not self._is_builtin_module(module):
                    # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„åŒ…æ£€æŸ¥é€»è¾‘
                    self.validation_results["dependencies"]["passed"] += 1

        except Exception as e:
            self.validation_results["dependencies"]["failed"] += 1
            self.validation_results["dependencies"]["issues"].append(
                {
                    "file": str(py_file),
                    "type": "import_check_error",
                    "message": f"å¯¼å…¥æ£€æŸ¥é”™è¯¯: {str(e)}",
                }
            )

    def _is_builtin_module(self, module_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå†…ç½®æ¨¡å—"""
        builtin_modules = {
            "os",
            "sys",
            "re",
            "json",
            "logging",
            "datetime",
            "pathlib",
            "subprocess",
            "argparse",
            "unittest",
            "tempfile",
            "shutil",
        }
        return module_name in builtin_modules

    def _check_powershell_modules(self, workflow_dir: Path):
        """æ£€æŸ¥PowerShellæ¨¡å—ä¾èµ–"""
        for ps_file in workflow_dir.glob("**/*.ps1"):
            try:
                content = ps_file.read_text(encoding="utf-8")
                modules = re.findall(r"Import-Module\s+([^\s]+)", content)

                for module in modules:
                    self.validation_results["dependencies"]["passed"] += 1

            except Exception as e:
                self.validation_results["dependencies"]["failed"] += 1
                self.validation_results["dependencies"]["issues"].append(
                    {
                        "file": str(ps_file),
                        "type": "powershell_module_error",
                        "message": f"PowerShellæ¨¡å—æ£€æŸ¥é”™è¯¯: {str(e)}",
                    }
                )

    def _check_system_dependencies(self, workflow_dir: Path):
        """æ£€æŸ¥ç³»ç»Ÿä¾èµ–"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ç³»ç»Ÿå‘½ä»¤è°ƒç”¨
        command_patterns = [
            r'subprocess\.run\(["\']([^"\']+)["\']',
            r'os\.system\(["\']([^"\']+)["\']',
            r'Invoke-Expression\s+["\']([^"\']+)["\']',
        ]

        for file_path in workflow_dir.glob("**/*"):
            if file_path.suffix in [".py", ".ps1"]:
                try:
                    content = file_path.read_text(encoding="utf-8")

                    for pattern in command_patterns:
                        commands = re.findall(pattern, content)
                        for command in commands:
                            # è¿™é‡Œå¯ä»¥æ·»åŠ å‘½ä»¤å¯ç”¨æ€§æ£€æŸ¥
                            self.validation_results["dependencies"]["passed"] += 1

                except Exception:
                    pass  # å¿½ç•¥æ–‡ä»¶è¯»å–é”™è¯¯

    def assess_quality(self, workflow_path: str):
        """è¯„ä¼°å·¥ä½œæµè´¨é‡ - å¢å¼ºç‰ˆæ”¯æŒæ’ä»¶ç³»ç»Ÿ"""
        logger.info("æ‰§è¡Œè´¨é‡è¯„ä¼°")

        workflow_dir = Path(workflow_path)

        # åŸºç¡€è´¨é‡è¯„ä¼°
        quality_scores = {
            "completeness": self._assess_completeness(workflow_dir),
            "usability": self._assess_usability(workflow_dir),
            "maintainability": self._assess_maintainability(workflow_dir),
            "documentation": self._assess_documentation(workflow_dir),
            "extensibility": self._assess_extensibility(workflow_dir),
        }

        # æ’ä»¶ç³»ç»Ÿå¢å¼ºè¯„ä¼°
        plugin_scores = {}
        if self.enable_plugins and self.plugin_manager:
            try:
                print("\nğŸ”Œ æ‰§è¡Œæ’ä»¶ç³»ç»Ÿè¯„ä¼°...")
                plugin_scores = self.plugin_manager.assess_all(workflow_dir)

                # æ£€æŸ¥æ˜¯å¦æœ‰ç»´åº¦è¦†ç›–é…ç½®
                dimension_overrides = self.plugin_manager.config.get(
                    "dimension_overrides", {}
                )

                for dimension, override_config in dimension_overrides.items():
                    if (
                        override_config.get("enabled", False)
                        and dimension in quality_scores
                    ):
                        # ä½¿ç”¨æ’ä»¶åˆ†æ•°è¦†ç›–åŸæœ‰ç»´åº¦
                        override_plugins = override_config.get("plugins", [])
                        override_weights = override_config.get("weights", [])

                        if len(override_plugins) == len(override_weights):
                            weighted_score = 0.0
                            total_weight = 0.0

                            for plugin_name, weight in zip(
                                override_plugins, override_weights
                            ):
                                if plugin_name in plugin_scores:
                                    weighted_score += (
                                        plugin_scores[plugin_name] * weight
                                    )
                                    total_weight += weight

                            if total_weight > 0:
                                quality_scores[dimension] = (
                                    weighted_score / total_weight
                                )
                                print(
                                    f"ğŸ”„ {dimension} ç»´åº¦å·²è¢«æ’ä»¶ç³»ç»Ÿè¦†ç›–: {quality_scores[dimension]:.1f}"
                                )

            except Exception as e:
                print(f"âš ï¸ æ’ä»¶è¯„ä¼°å¤±è´¥: {e}")

        # è®¡ç®—ç»¼åˆåˆ†æ•°
        weights = {
            "completeness": 0.30,  # æé«˜å®Œæ•´æ€§æƒé‡
            "usability": 0.25,  # æé«˜å¯ç”¨æ€§æƒé‡
            "maintainability": 0.25,  # æé«˜å¯ç»´æŠ¤æ€§æƒé‡
            "documentation": 0.10,  # ä¿æŒæ–‡æ¡£æƒé‡
            "extensibility": 0.10,  # ä¿æŒæ‰©å±•æ€§æƒé‡
        }

        total_score = sum(
            quality_scores[dimension] * weights[dimension]
            for dimension in quality_scores
        )

        self.validation_results["quality"]["score"] = total_score
        self.validation_results["quality"]["details"] = quality_scores

        # ä¿å­˜æ’ä»¶è¯„ä¼°ç»“æœ
        if plugin_scores:
            self.validation_results["quality"]["plugin_scores"] = plugin_scores
        self.validation_results["quality"]["details"] = quality_scores

    def _assess_completeness(self, workflow_dir: Path) -> float:
        """è¯„ä¼°åŠŸèƒ½å®Œæ•´æ€§"""
        score = 0.0
        total_checks = 6

        # æ£€æŸ¥1: ä¸»è¦æ¨¡æ¿æ–‡ä»¶
        if any(
            workflow_dir.glob(pattern) for pattern in ["*_template.md", "*_workflow.md"]
        ):
            score += 1

        # æ£€æŸ¥2: READMEæ–‡æ¡£
        if any(workflow_dir.glob("README.md")):
            score += 1

        # æ£€æŸ¥3: å·¥å…·è„šæœ¬æ–‡ä»¶ (Pythonæˆ–PowerShellï¼Œæœ‰å…¶ä¸­ä¹‹ä¸€å³å¯)
        if any(workflow_dir.glob("**/*.py")) or any(workflow_dir.glob("**/*.ps1")):
            score += 2  # åˆå¹¶Pythonå’ŒPowerShellæ£€æŸ¥ï¼Œç»™2åˆ†

        # æ£€æŸ¥4: å¼ºåˆ¶æ ¸å¿ƒæ–‡ä»¶å¤¹ç»“æ„ (æ ¹æ®workflow_builder_template.mdæ­¥éª¤5.1)
        required_dirs = ["templates", "docs", "tools"]  # scriptsæ”¹ä¸ºtoolsï¼Œæ›´ç¬¦åˆå®é™…
        existing_dirs = 0
        for req_dir in required_dirs:
            if (workflow_dir / req_dir).exists():
                existing_dirs += 1
        # æŒ‰æ¯”ä¾‹ç»™åˆ†ï¼šå…¨éƒ¨å­˜åœ¨ç»™1åˆ†ï¼Œ2/3å­˜åœ¨ç»™0.67åˆ†ï¼Œ1/3å­˜åœ¨ç»™0.33åˆ†
        score += existing_dirs / len(required_dirs)

        # æ£€æŸ¥5: æµ‹è¯•æ–‡ä»¶
        if any(workflow_dir.glob("**/test_*.py")):
            score += 1

        # æ£€æŸ¥6: é…ç½®æ–‡ä»¶
        if any(workflow_dir.glob("**/*.json")) or any(workflow_dir.glob("**/*.yaml")):
            score += 1

        return (score / total_checks) * 10

    def _assess_usability(self, workflow_dir: Path) -> float:
        """è¯„ä¼°æ˜“ç”¨æ€§"""
        score = 0.0
        total_checks = 5

        # æ£€æŸ¥ä½¿ç”¨æŒ‡å¯¼
        for md_file in workflow_dir.glob("**/*.md"):
            if self._should_exclude_file(md_file, workflow_dir):
                continue
            content = md_file.read_text(encoding="utf-8")
            if "ä½¿ç”¨æŒ‡å¯¼" in content or "å¿«é€Ÿå¼€å§‹" in content:
                score += 1
                break

        # æ£€æŸ¥ç¤ºä¾‹ä»£ç 
        for md_file in workflow_dir.glob("**/*.md"):
            if self._should_exclude_file(md_file, workflow_dir):
                continue
            content = md_file.read_text(encoding="utf-8")
            if "```" in content:
                score += 1
                break

        # æ£€æŸ¥é”™è¯¯å¤„ç†è¯´æ˜
        for file_path in workflow_dir.glob("**/*"):
            if self._should_exclude_file(file_path, workflow_dir):
                continue
            if file_path.suffix in [".md", ".py", ".ps1"]:
                content = file_path.read_text(encoding="utf-8")
                if "é”™è¯¯" in content or "å¼‚å¸¸" in content or "æ•…éšœ" in content:
                    score += 1
                    break

        # æ£€æŸ¥é…ç½®è¯´æ˜
        for md_file in workflow_dir.glob("**/*.md"):
            if self._should_exclude_file(md_file, workflow_dir):
                continue
            content = md_file.read_text(encoding="utf-8")
            if "é…ç½®" in content or "è®¾ç½®" in content:
                score += 1
                break

        # æ£€æŸ¥FAQæˆ–æ•…éšœæ’é™¤
        for md_file in workflow_dir.glob("**/*.md"):
            if self._should_exclude_file(md_file, workflow_dir):
                continue
            content = md_file.read_text(encoding="utf-8")
            if "FAQ" in content or "æ•…éšœæ’é™¤" in content or "å¸¸è§é—®é¢˜" in content:
                score += 1
                break

        return (score / total_checks) * 10

    def _assess_maintainability(self, workflow_dir: Path) -> float:
        """
        è¯„ä¼°å¯ç»´æŠ¤æ€§

        æ£€æŸ¥ä»£ç çš„å¯ç»´æŠ¤æ€§æ–¹é¢ï¼ŒåŒ…æ‹¬æ³¨é‡Šè´¨é‡ã€é¢å‘å¯¹è±¡è®¾è®¡ã€
        ç‰ˆæœ¬æ§åˆ¶ä¿¡æ¯å’Œæ—¥å¿—è®°å½•ç­‰æ–¹é¢ã€‚

        Args:
            workflow_dir (Path): å·¥ä½œæµç›®å½•è·¯å¾„

        Returns:
            float: å¯ç»´æŠ¤æ€§å¾—åˆ† (0-10åˆ†)

        Note:
            è¯„åˆ†æ ‡å‡†ï¼š
            1. ä»£ç æ³¨é‡Šç‡ >= 10% (2.5åˆ†)
            2. é¢å‘å¯¹è±¡è®¾è®¡ - ä½¿ç”¨ç±» (2.5åˆ†)
            3. ç‰ˆæœ¬æ§åˆ¶ä¿¡æ¯å­˜åœ¨ (2.5åˆ†)
            4. æ—¥å¿—è®°å½•æœºåˆ¶ (2.5åˆ†)
        """
        logger.debug("å¼€å§‹è¯„ä¼°å¯ç»´æŠ¤æ€§")
        score = 0.0
        total_checks = 4

        # 1. æ£€æŸ¥ä»£ç æ³¨é‡Šç‡
        python_files = list(workflow_dir.glob("**/*.py"))
        if python_files:
            total_lines = 0
            comment_lines = 0

            for py_file in python_files:
                try:
                    content = py_file.read_text(encoding="utf-8")
                    lines = content.split("\n")
                    total_lines += len(lines)
                    # ç»Ÿè®¡æ³¨é‡Šè¡Œï¼ˆä»¥#å¼€å¤´ï¼Œæˆ–åŒ…å«docstringï¼‰
                    comment_lines += sum(
                        1
                        for line in lines
                        if line.strip().startswith("#")
                        or '"""' in line
                        or "'''" in line
                    )
                except Exception as e:
                    logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {py_file}: {e}")

            if total_lines > 0:
                comment_ratio = comment_lines / total_lines
                if comment_ratio >= 0.1:
                    score += 1
                    logger.debug(f"æ³¨é‡Šç‡é€šè¿‡: {comment_ratio:.2%}")
                else:
                    logger.debug(f"æ³¨é‡Šç‡ä¸è¶³: {comment_ratio:.2%} < 10%")

        # 2. æ£€æŸ¥é¢å‘å¯¹è±¡è®¾è®¡ - æ”¹è¿›çš„æ¨¡å—åŒ–è¯„åˆ†æ ‡å‡†
        oo_design_score = self._check_object_oriented_design(python_files)
        if oo_design_score > 0:
            score += 1
            logger.debug("é¢å‘å¯¹è±¡è®¾è®¡æ£€æŸ¥é€šè¿‡")
        else:
            logger.debug("æœªå‘ç°é¢å‘å¯¹è±¡è®¾è®¡æ¨¡å¼")

        # 3. æ£€æŸ¥ç‰ˆæœ¬æ§åˆ¶ä¿¡æ¯
        version_found = False
        for md_file in workflow_dir.glob("**/*.md"):
            try:
                content = md_file.read_text(encoding="utf-8")
                if "ç‰ˆæœ¬" in content or "version" in content.lower():
                    score += 1
                    version_found = True
                    logger.debug(f"åœ¨ {md_file} ä¸­å‘ç°ç‰ˆæœ¬ä¿¡æ¯")
                    break
            except Exception as e:
                logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {md_file}: {e}")

        if not version_found:
            logger.debug("æœªå‘ç°ç‰ˆæœ¬æ§åˆ¶ä¿¡æ¯")

        # 4. æ£€æŸ¥æ—¥å¿—è®°å½•æœºåˆ¶
        logging_found = False
        for py_file in python_files:
            try:
                content = py_file.read_text(encoding="utf-8")
                if "logging" in content or "logger" in content:
                    score += 1
                    logging_found = True
                    logger.debug(f"åœ¨ {py_file} ä¸­å‘ç°æ—¥å¿—è®°å½•")
                    break
            except Exception as e:
                logger.warning(f"è¯»å–æ–‡ä»¶å¤±è´¥ {py_file}: {e}")

        if not logging_found:
            logger.debug("æœªå‘ç°æ—¥å¿—è®°å½•æœºåˆ¶")

        final_score = (score / total_checks) * 10
        logger.info(
            f"å¯ç»´æŠ¤æ€§è¯„ä¼°å®Œæˆ: {final_score:.1f}/10.0 ({score}/{total_checks} é¡¹é€šè¿‡)"
        )
        return final_score

    def _check_object_oriented_design(self, python_files: List[Path]) -> float:
        """
        æ£€æŸ¥é¢å‘å¯¹è±¡è®¾è®¡

        æ£€æŸ¥Pythonä»£ç æ˜¯å¦ä½¿ç”¨äº†é¢å‘å¯¹è±¡çš„è®¾è®¡æ¨¡å¼ï¼Œ
        è€Œä¸æ˜¯ç®€å•åœ°æ ¹æ®æ–‡ä»¶æ•°é‡åˆ¤æ–­æ¨¡å—åŒ–ç¨‹åº¦ã€‚

        Args:
            python_files (List[Path]): Pythonæ–‡ä»¶åˆ—è¡¨

        Returns:
            float: é¢å‘å¯¹è±¡è®¾è®¡å¾—åˆ† (0-1)

        Note:
            è¯„åˆ†æ ‡å‡†ï¼š
            - å‘ç°ç±»å®šä¹‰ (+0.5)
            - å‘ç°ç»§æ‰¿å…³ç³» (+0.2)
            - å‘ç°æ–¹æ³•å®šä¹‰ (+0.2)
            - å‘ç°è£…é¥°å™¨ä½¿ç”¨ (+0.1)
        """
        if not python_files:
            return 0.0

        oo_score = 0.0

        # ç»Ÿè®¡å„ç§é¢å‘å¯¹è±¡ç‰¹å¾
        class_count = 0
        inheritance_count = 0
        method_count = 0
        decorator_count = 0

        for py_file in python_files:
            try:
                content = py_file.read_text(encoding="utf-8")

                # æ£€æŸ¥ç±»å®šä¹‰
                class_matches = re.findall(r"^class\s+\w+", content, re.MULTILINE)
                class_count += len(class_matches)

                # æ£€æŸ¥ç»§æ‰¿å…³ç³»
                inheritance_matches = re.findall(
                    r"^class\s+\w+\([^)]+\)", content, re.MULTILINE
                )
                inheritance_count += len(inheritance_matches)

                # æ£€æŸ¥æ–¹æ³•å®šä¹‰ï¼ˆåœ¨ç±»å†…éƒ¨ï¼‰
                method_matches = re.findall(r"^\s+def\s+\w+", content, re.MULTILINE)
                method_count += len(method_matches)

                # æ£€æŸ¥è£…é¥°å™¨ä½¿ç”¨
                decorator_matches = re.findall(r"^\s*@\w+", content, re.MULTILINE)
                decorator_count += len(decorator_matches)

            except Exception as e:
                logger.warning(f"åˆ†ææ–‡ä»¶å¤±è´¥ {py_file}: {e}")

        # æ ¹æ®å‘ç°çš„OOç‰¹å¾è®¡åˆ†
        if class_count > 0:
            oo_score += 0.5
            logger.debug(f"å‘ç° {class_count} ä¸ªç±»å®šä¹‰")

        if inheritance_count > 0:
            oo_score += 0.2
            logger.debug(f"å‘ç° {inheritance_count} ä¸ªç»§æ‰¿å…³ç³»")

        if method_count > 0:
            oo_score += 0.2
            logger.debug(f"å‘ç° {method_count} ä¸ªæ–¹æ³•å®šä¹‰")

        if decorator_count > 0:
            oo_score += 0.1
            logger.debug(f"å‘ç° {decorator_count} ä¸ªè£…é¥°å™¨")

        # ç¡®ä¿å¾—åˆ†åœ¨0-1èŒƒå›´å†…
        oo_score = min(1.0, oo_score)
        logger.debug(f"é¢å‘å¯¹è±¡è®¾è®¡å¾—åˆ†: {oo_score:.1f}")

        return oo_score

    def _assess_documentation(self, workflow_dir: Path) -> float:
        """è¯„ä¼°æ–‡æ¡£è´¨é‡"""
        score = 0.0
        total_checks = 4

        # æ£€æŸ¥READMEå­˜åœ¨
        if any(workflow_dir.glob("README.md")):
            score += 1

        # æ£€æŸ¥æ–‡æ¡£ç»“æ„å®Œæ•´æ€§
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if all(section in content for section in ["ç›®æ ‡", "ä½¿ç”¨", "æ­¥éª¤"]):
                score += 1
                break

        # æ£€æŸ¥ä»£ç æ–‡æ¡£
        for py_file in workflow_dir.glob("**/*.py"):
            content = py_file.read_text(encoding="utf-8")
            if '"""' in content or "def " in content:
                score += 1
                break

        # æ£€æŸ¥æ–‡æ¡£æ›´æ–°æ—¶é—´
        for md_file in workflow_dir.glob("**/*.md"):
            content = md_file.read_text(encoding="utf-8")
            if "åˆ›å»ºæ—¶é—´" in content or "æ›´æ–°æ—¶é—´" in content:
                score += 1
                break

        return (score / total_checks) * 10

    def _assess_extensibility(self, workflow_dir: Path) -> float:
        """è¯„ä¼°æ‰©å±•æ€§"""
        score = 0.0
        total_checks = 3

        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        if any(workflow_dir.glob("**/*.json")) or any(workflow_dir.glob("**/*.yaml")):
            score += 1

        # æ£€æŸ¥æ¨¡æ¿æ–‡ä»¶
        if any(workflow_dir.glob("**/template*")):
            score += 1

        # æ£€æŸ¥æ’ä»¶æˆ–æ‰©å±•ç‚¹
        for py_file in workflow_dir.glob("**/*.py"):
            content = py_file.read_text(encoding="utf-8")
            if "plugin" in content.lower() or "extend" in content.lower():
                score += 1
                break

        return (score / total_checks) * 10

    def _generate_validation_report(self) -> Dict[str, Any]:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        total_syntax = (
            self.validation_results["syntax"]["passed"]
            + self.validation_results["syntax"]["failed"]
        )
        total_logic = (
            self.validation_results["logic"]["passed"]
            + self.validation_results["logic"]["failed"]
        )
        total_deps = (
            self.validation_results["dependencies"]["passed"]
            + self.validation_results["dependencies"]["failed"]
        )

        report = {
            "summary": {
                "overall_status": (
                    "PASS" if len(self._get_critical_issues()) == 0 else "FAIL"
                ),
                "total_issues": len(self._get_all_issues()),
                "critical_issues": len(self._get_critical_issues()),
                "quality_score": self.validation_results["quality"]["score"],
            },
            "syntax_validation": {
                "status": (
                    "PASS"
                    if self.validation_results["syntax"]["failed"] == 0
                    else "FAIL"
                ),
                "total_checks": total_syntax,
                "passed": self.validation_results["syntax"]["passed"],
                "failed": self.validation_results["syntax"]["failed"],
                "issues": self.validation_results["syntax"]["issues"],
            },
            "logic_validation": {
                "status": (
                    "PASS"
                    if self.validation_results["logic"]["failed"] == 0
                    else "FAIL"
                ),
                "total_checks": total_logic,
                "passed": self.validation_results["logic"]["passed"],
                "failed": self.validation_results["logic"]["failed"],
                "issues": self.validation_results["logic"]["issues"],
            },
            "dependency_validation": {
                "status": (
                    "PASS"
                    if self.validation_results["dependencies"]["failed"] == 0
                    else "FAIL"
                ),
                "total_checks": total_deps,
                "passed": self.validation_results["dependencies"]["passed"],
                "failed": self.validation_results["dependencies"]["failed"],
                "issues": self.validation_results["dependencies"]["issues"],
            },
            "quality_assessment": {
                "overall_score": self.validation_results["quality"]["score"],
                "grade": self._get_quality_grade(
                    self.validation_results["quality"]["score"]
                ),
                "details": self.validation_results["quality"]["details"],
            },
        }

        return report

    def _get_all_issues(self) -> List[Dict]:
        """è·å–æ‰€æœ‰é—®é¢˜"""
        all_issues = []
        all_issues.extend(self.validation_results["syntax"]["issues"])
        all_issues.extend(self.validation_results["logic"]["issues"])
        all_issues.extend(self.validation_results["dependencies"]["issues"])
        return all_issues

    def _get_critical_issues(self) -> List[Dict]:
        """è·å–å…³é”®é—®é¢˜"""
        critical_types = [
            "missing_main_workflow",
            "python_syntax",
            "missing_section",
            "broken_link",
        ]

        return [
            issue
            for issue in self._get_all_issues()
            if issue.get("type") in critical_types
        ]

    def _get_quality_grade(self, score: float) -> str:
        """è·å–è´¨é‡ç­‰çº§"""
        if score >= 8.5:
            return "ä¼˜ç§€"
        elif score >= 7.0:
            return "è‰¯å¥½"
        elif score >= 6.0:
            return "åŠæ ¼"
        else:
            return "ä¸åŠæ ¼"


def main():
    """CLIå…¥å£å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="å·¥ä½œæµéªŒè¯å™¨")
    parser.add_argument("workflow_path", help="å·¥ä½œæµç›®å½•è·¯å¾„")
    parser.add_argument("--output", help="æŠ¥å‘Šè¾“å‡ºæ–‡ä»¶")
    parser.add_argument(
        "--format", choices=["json", "text"], default="text", help="æŠ¥å‘Šæ ¼å¼"
    )
    parser.add_argument(
        "--exclude",
        action="append",
        help="æ’é™¤çš„æ–‡ä»¶æˆ–ç›®å½•æ¨¡å¼ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰ï¼Œå¯å¤šæ¬¡ä½¿ç”¨",
    )

    args = parser.parse_args()

    # åˆ›å»ºéªŒè¯å™¨
    validator = WorkflowValidator(exclude_patterns=args.exclude)

    # æ‰§è¡ŒéªŒè¯
    report = validator.validate_workflow(args.workflow_path)

    # è¾“å‡ºæŠ¥å‘Š
    if args.format == "json":
        output = json.dumps(report, ensure_ascii=False, indent=2)
    else:
        output = _format_text_report(report)

    if args.output:
        with open(args.output, "w", encoding="utf-8") as f:
            f.write(output)
        print(f"âœ… éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: {args.output}")
    else:
        print(output)


def _format_text_report(report: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–æ–‡æœ¬æŠ¥å‘Š"""
    summary = report["summary"]

    output = f"""
# å·¥ä½œæµéªŒè¯æŠ¥å‘Š

## ğŸ“Š æ€»ä½“çŠ¶æ€
- **éªŒè¯çŠ¶æ€**: {summary["overall_status"]}
- **è´¨é‡è¯„åˆ†**: {summary["quality_score"]:.1f}/10.0 ({report["quality_assessment"]["grade"]})
- **é—®é¢˜æ€»æ•°**: {summary["total_issues"]}
- **å…³é”®é—®é¢˜**: {summary["critical_issues"]}

## ğŸ” è¯¦ç»†ç»“æœ

### è¯­æ³•éªŒè¯
- **çŠ¶æ€**: {report["syntax_validation"]["status"]}
- **é€šè¿‡**: {report["syntax_validation"]["passed"]}
- **å¤±è´¥**: {report["syntax_validation"]["failed"]}

### é€»è¾‘éªŒè¯
- **çŠ¶æ€**: {report["logic_validation"]["status"]}
- **é€šè¿‡**: {report["logic_validation"]["passed"]}
- **å¤±è´¥**: {report["logic_validation"]["failed"]}

### ä¾èµ–éªŒè¯
- **çŠ¶æ€**: {report["dependency_validation"]["status"]}
- **é€šè¿‡**: {report["dependency_validation"]["passed"]}
- **å¤±è´¥**: {report["dependency_validation"]["failed"]}

## ğŸ“ˆ è´¨é‡è¯„ä¼°è¯¦æƒ…
"""

    for dimension, score in report["quality_assessment"]["details"].items():
        output += f"- **{dimension}**: {score:.1f}/10.0\n"

    # æ·»åŠ æ’ä»¶è¯„ä¼°ç»“æœ
    if "plugin_scores" in report["quality_assessment"]:
        output += "\n## ğŸ”Œ æ’ä»¶ç³»ç»Ÿè¯„ä¼°\n"
        for plugin_name, score in report["quality_assessment"]["plugin_scores"].items():
            output += f"- **{plugin_name}**: {score:.1f}/10.0\n"

    # æ·»åŠ é—®é¢˜è¯¦æƒ…
    all_issues = []
    all_issues.extend(report["syntax_validation"]["issues"])
    all_issues.extend(report["logic_validation"]["issues"])
    all_issues.extend(report["dependency_validation"]["issues"])

    if all_issues:
        output += "\n## âš ï¸ é—®é¢˜è¯¦æƒ…\n"
        for issue in all_issues:
            output += f"- **{issue['type']}**: {issue['message']}\n"
            if "file" in issue:
                output += f"  - æ–‡ä»¶: {issue['file']}\n"
            if "line" in issue:
                output += f"  - è¡Œå·: {issue['line']}\n"

    return output


if __name__ == "__main__":
    main()
