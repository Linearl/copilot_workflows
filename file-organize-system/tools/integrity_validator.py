#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶æ•´ç†å®Œæ•´æ€§éªŒè¯å·¥å…·
éªŒè¯æ–‡ä»¶æ•´ç†è¿‡ç¨‹çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
"""

import os
import json
import argparse
from pathlib import Path
from collections import defaultdict

class IntegrityValidator:
    def __init__(self):
        self.original_files = {}
        self.organized_files = {}
        self.issues = []
    
    def scan_directory(self, directory, recursive=True):
        """æ‰«æç›®å½•ï¼Œè·å–æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯"""
        files = {}
        directory = Path(directory)
        
        if not directory.exists():
            return files
        
        if recursive:
            pattern = "**/*"
        else:
            pattern = "*"
        
        for file_path in directory.glob(pattern):
            if file_path.is_file():
                try:
                    stat = file_path.stat()
                    relative_path = str(file_path.relative_to(directory))
                    files[relative_path] = {
                        'name': file_path.name,
                        'size': stat.st_size,
                        'mtime': stat.st_mtime,
                        'path': str(file_path)
                    }
                except Exception as e:
                    print(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        
        return files
    
    def validate_original_empty(self, original_dir, organized_dir=None):
        """éªŒè¯åŸç›®å½•æ˜¯å¦å®Œå…¨æ¸…ç©º"""
        print(f"æ£€æŸ¥åŸç›®å½•æ˜¯å¦æ¸…ç©º: {original_dir}")
        
        remaining_files = self.scan_directory(original_dir)
        
        # æ’é™¤å·²æ•´ç†ç›®å½•
        if organized_dir:
            organized_relative = os.path.relpath(organized_dir, original_dir)
            remaining_files = {
                k: v for k, v in remaining_files.items() 
                if not k.startswith(organized_relative)
            }
        
        if remaining_files:
            self.issues.append({
                'type': 'incomplete_cleanup',
                'severity': 'high',
                'message': f'åŸç›®å½•ä¸­ä»æœ‰ {len(remaining_files)} ä¸ªæ–‡ä»¶æœªå¤„ç†',
                'files': list(remaining_files.keys())
            })
            print(f"âš ï¸ å‘ç° {len(remaining_files)} ä¸ªæœªå¤„ç†çš„æ–‡ä»¶:")
            for file_path in remaining_files:
                print(f"  - {file_path}")
            return False
        else:
            print("âœ… åŸç›®å½•å·²å®Œå…¨æ¸…ç©º")
            return True
    
    def validate_file_integrity(self, before_dir, after_dir):
        """éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼ˆæ–‡ä»¶æ•°é‡ã€å¤§å°ç­‰ï¼‰"""
        print(f"éªŒè¯æ–‡ä»¶å®Œæ•´æ€§...")
        
        before_files = self.scan_directory(before_dir)
        after_files = self.scan_directory(after_dir)
        
        # æŒ‰å¤§å°å’Œåç§°åŒ¹é…æ–‡ä»¶
        before_by_size_name = defaultdict(list)
        after_by_size_name = defaultdict(list)
        
        for path, info in before_files.items():
            key = (info['size'], info['name'])
            before_by_size_name[key].append(path)
        
        for path, info in after_files.items():
            key = (info['size'], info['name'])
            after_by_size_name[key].append(path)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ä¸¢å¤±
        missing_files = []
        for key, paths in before_by_size_name.items():
            if key not in after_by_size_name:
                missing_files.extend(paths)
            elif len(paths) > len(after_by_size_name[key]):
                # éƒ¨åˆ†æ–‡ä»¶ä¸¢å¤±
                missing_count = len(paths) - len(after_by_size_name[key])
                missing_files.extend(paths[:missing_count])
        
        if missing_files:
            self.issues.append({
                'type': 'missing_files',
                'severity': 'high',
                'message': f'æœ‰ {len(missing_files)} ä¸ªæ–‡ä»¶å¯èƒ½ä¸¢å¤±',
                'files': missing_files
            })
            print(f"âš ï¸ å¯èƒ½ä¸¢å¤±çš„æ–‡ä»¶:")
            for file_path in missing_files:
                print(f"  - {file_path}")
            return False
        
        # æ£€æŸ¥æ–‡ä»¶æ•°é‡
        if len(before_files) != len(after_files):
            self.issues.append({
                'type': 'file_count_mismatch',
                'severity': 'medium',
                'message': f'æ–‡ä»¶æ•°é‡ä¸åŒ¹é…: åŸ{len(before_files)}ä¸ªï¼Œç°{len(after_files)}ä¸ª'
            })
            print(f"âš ï¸ æ–‡ä»¶æ•°é‡ä¸åŒ¹é…: åŸ{len(before_files)}ä¸ªï¼Œç°{len(after_files)}ä¸ª")
        else:
            print(f"âœ… æ–‡ä»¶æ•°é‡åŒ¹é…: {len(after_files)}ä¸ªæ–‡ä»¶")
        
        return len(missing_files) == 0
    
    def validate_classification(self, organized_dir, classification_rules=None):
        """éªŒè¯æ–‡ä»¶åˆ†ç±»çš„æ­£ç¡®æ€§"""
        print("éªŒè¯æ–‡ä»¶åˆ†ç±»...")
        
        organized_files = self.scan_directory(organized_dir)
        misclassified = []
        
        # åŸºæœ¬åˆ†ç±»è§„åˆ™
        default_rules = {
            '01_å­¦æœ¯æ•™è‚²èµ„æ–™': ['.pdf', '.docx', '.doc', '.pptx', '.ppt'],
            '02_æ”¿ç­–æ³•è§„æ–‡æ¡£': ['.pdf', '.docx', '.doc'],
            '03_å•†ä¸šæŠ•èµ„èµ„æ–™': ['.pdf', '.xlsx', '.xls', '.docx'],
            '04_è½¯ä»¶å·¥å…·': ['.exe', '.msi', '.zip', '.7z', '.rar'],
            '05_åŠå…¬æ–‡æ¡£': ['.docx', '.doc', '.xlsx', '.xls', '.pptx', '.ppt'],
            '06_åª’ä½“æ–‡ä»¶': ['.mp4', '.avi', '.mkv', '.jpg', '.png', '.gif'],
            '07_æ•°æ®åˆ†æ': ['.csv', '.xlsx', '.xls', '.json', '.xml'],
            '99_å¾…ç¡®è®¤': []  # ä»»ä½•ç±»å‹éƒ½å¯ä»¥
        }
        
        rules = classification_rules or default_rules
        
        for file_path, file_info in organized_files.items():
            # è·å–æ–‡ä»¶æ‰€åœ¨çš„åˆ†ç±»ç›®å½•
            parts = file_path.split(os.sep)
            if len(parts) < 2:
                continue
                
            category = parts[0]
            file_ext = Path(file_info['name']).suffix.lower()
            
            # æ£€æŸ¥åˆ†ç±»æ˜¯å¦æ­£ç¡®
            if category in rules and rules[category]:
                if file_ext not in rules[category]:
                    misclassified.append({
                        'file': file_path,
                        'category': category,
                        'extension': file_ext,
                        'expected_extensions': rules[category]
                    })
        
        if misclassified:
            self.issues.append({
                'type': 'misclassification',
                'severity': 'low',
                'message': f'æœ‰ {len(misclassified)} ä¸ªæ–‡ä»¶å¯èƒ½åˆ†ç±»é”™è¯¯',
                'details': misclassified
            })
            print(f"âš ï¸ å¯èƒ½åˆ†ç±»é”™è¯¯çš„æ–‡ä»¶:")
            for item in misclassified:
                print(f"  - {item['file']} (ç±»å‹{item['extension']}, åœ¨{item['category']})")
        else:
            print("âœ… æ–‡ä»¶åˆ†ç±»éªŒè¯é€šè¿‡")
        
        return len(misclassified) == 0
    
    def generate_report(self, output_file=None):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = {
            'validation_time': os.popen('date').read().strip(),
            'total_issues': len(self.issues),
            'issues_by_severity': {
                'high': len([i for i in self.issues if i['severity'] == 'high']),
                'medium': len([i for i in self.issues if i['severity'] == 'medium']),
                'low': len([i for i in self.issues if i['severity'] == 'low'])
            },
            'issues': self.issues
        }
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            print(f"éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        
        return report
    
    def print_summary(self):
        """æ‰“å°éªŒè¯ç»“æœæ‘˜è¦"""
        print("\n" + "="*50)
        print("ğŸ“Š éªŒè¯ç»“æœæ‘˜è¦")
        print("="*50)
        
        if not self.issues:
            print("âœ… æ‰€æœ‰éªŒè¯é¡¹ç›®éƒ½é€šè¿‡äº†ï¼æ•´ç†å·¥ä½œå®Œæˆå¾—å¾ˆå¥½ã€‚")
        else:
            high_issues = [i for i in self.issues if i['severity'] == 'high']
            medium_issues = [i for i in self.issues if i['severity'] == 'medium']
            low_issues = [i for i in self.issues if i['severity'] == 'low']
            
            print(f"æ€»é—®é¢˜æ•°: {len(self.issues)}")
            if high_issues:
                print(f"ğŸ”´ é«˜ä¼˜å…ˆçº§é—®é¢˜: {len(high_issues)}ä¸ª")
            if medium_issues:
                print(f"ğŸŸ¡ ä¸­ä¼˜å…ˆçº§é—®é¢˜: {len(medium_issues)}ä¸ª")
            if low_issues:
                print(f"ğŸŸ¢ ä½ä¼˜å…ˆçº§é—®é¢˜: {len(low_issues)}ä¸ª")
        
        print("="*50)

def main():
    parser = argparse.ArgumentParser(description='æ–‡ä»¶æ•´ç†å®Œæ•´æ€§éªŒè¯å·¥å…·')
    parser.add_argument('--original', required=True, help='åŸå§‹ç›®å½•è·¯å¾„')
    parser.add_argument('--organized', help='æ•´ç†åçš„ç›®å½•è·¯å¾„')
    parser.add_argument('--backup', help='å¤‡ä»½ç›®å½•è·¯å¾„ï¼ˆç”¨äºå®Œæ•´æ€§å¯¹æ¯”ï¼‰')
    parser.add_argument('--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--skip-empty-check', action='store_true', help='è·³è¿‡åŸç›®å½•æ¸…ç©ºæ£€æŸ¥')
    
    args = parser.parse_args()
    
    validator = IntegrityValidator()
    
    print("ğŸ” å¼€å§‹æ–‡ä»¶æ•´ç†å®Œæ•´æ€§éªŒè¯...")
    print(f"åŸå§‹ç›®å½•: {args.original}")
    if args.organized:
        print(f"æ•´ç†åç›®å½•: {args.organized}")
    if args.backup:
        print(f"å¤‡ä»½ç›®å½•: {args.backup}")
    print("-" * 50)
    
    # æ£€æŸ¥åŸç›®å½•æ˜¯å¦æ¸…ç©º
    if not args.skip_empty_check:
        validator.validate_original_empty(args.original, args.organized)
    
    # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
    if args.backup and args.organized:
        validator.validate_file_integrity(args.backup, args.organized)
    
    # æ£€æŸ¥åˆ†ç±»æ­£ç¡®æ€§
    if args.organized:
        validator.validate_classification(args.organized)
    
    # ç”ŸæˆæŠ¥å‘Š
    validator.generate_report(args.output)
    validator.print_summary()

if __name__ == '__main__':
    main()
